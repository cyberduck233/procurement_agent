from __future__ import annotations

import json
import logging
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, AsyncGenerator, Dict, Generator, List, Optional, Literal

import httpx
from fastapi import Depends, FastAPI, File, Form, HTTPException, UploadFile, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, ConfigDict, Field
from sqlalchemy.orm import Session

from .config import Settings, get_settings
from .database import (
    ToolRecord,
    get_session_factory,
    get_tool_by_id,
    init_engine,
    list_tool_logs,
    list_tools,
)
from .rag_service import (
    RetrievedContext,
    delete_document,
    ingest_document,
    list_documents,
    retrieve_context,
)
from .tool_service import (
    build_tool_prompt,
    execute_tool,
    list_builtin_options,
    load_tool_config,
    parse_tool_call,
    validate_tool_config,
)
from .graph_agent import run_agent, stream_agent, is_simple_query
from .file_processor import FileProcessor, chunk_text
from .rag_service import ingest_text_chunk

from .agent_roles import list_available_agents
from .memory_service import (
    retrieve_relevant_memories,
    save_conversation_and_extract_memories,
    format_memories_for_prompt,
    delete_memory_complete,
    extract_memories_from_conversation,
)
from .auth import (
    authenticate_user,
    create_access_token,
    create_refresh_token,
    get_password_hash,
    verify_token,
)
from .database import (
    ConversationHistory,
    PromptTemplate,
    User,
    Memory,
    SessionConfig,
    UserPreferences,
    get_conversation_history,
    list_conversation_sessions,
    search_conversation_sessions,
    delete_conversation_session,
    delete_conversation_message,
    get_prompt_template_by_id,
    get_active_prompt_for_agent,
    list_prompt_templates,
    create_prompt_template,
    update_prompt_template,
    create_memory,
    get_memory_by_id,
    search_memories,
    update_memory,
    delete_memory,
    delete_memories_batch,
    get_session_config,
    update_session_config,
    get_user_preferences,
    update_user_preferences,
    activate_prompt_template,
    delete_prompt_template,
)


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # è¯¾ç¨‹å¤§ä½œä¸šå¯æ”¾å¼€ï¼Œå®é™…ç¯å¢ƒè¯·é™åˆ¶åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ·»åŠ è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
@app.middleware("http")
async def log_requests(request, call_next):
    logger.info(f"ğŸŒ æ”¶åˆ°è¯·æ±‚: {request.method} {request.url.path}")
    response = await call_next(request)
    logger.info(f"ğŸ“¤ å“åº”çŠ¶æ€: {response.status_code}")
    return response


class Message(BaseModel):
    role: str
    content: str


class ChatRequest(BaseModel):
    messages: List[Message]
    model: str = Field(default="deepseek-r1", description="DeepSeek æ¨¡å‹ ID")
    temperature: float = Field(default=0.7, ge=0, le=2)
    max_tokens: Optional[int] = Field(default=None, ge=1)
    use_knowledge_base: bool = Field(
        default=False, description="æ˜¯å¦å¯ç”¨çŸ¥è¯†åº“æ£€ç´¢å¢å¼ºï¼ˆRAGï¼‰ã€‚"
    )
    top_k: int = Field(
        default=4,
        ge=1,
        le=10,
        description="çŸ¥è¯†åº“æ£€ç´¢è¿”å›çš„ç‰‡æ®µæ•°é‡ã€‚",
    )
    use_tools: bool = Field(
        default=False, description="æ˜¯å¦å…è®¸ä»£ç†è°ƒç”¨ MCP å·¥å…·ã€‚"
    )
    tool_ids: Optional[List[str]] = Field(
        default=None, description="å¯é€‰ï¼Œé™åˆ¶å¯ç”¨çš„å·¥å…· ID åˆ—è¡¨ã€‚"
    )
    session_id: Optional[str] = Field(
        default=None, description="ä¼šè¯IDï¼Œç”¨äºé•¿æœŸè®°å¿†å’Œå¯¹è¯å†å²ã€‚"
    )
    user_id: Optional[str] = Field(
        default=None, description="ç”¨æˆ·IDï¼Œç”¨äºå¤šç”¨æˆ·åœºæ™¯ã€‚"
    )


class ContextSnippet(BaseModel):
    document_id: Optional[str]
    original_name: Optional[str]
    content: str


class ToolExecutionResult(BaseModel):
    tool_id: str
    tool_name: str
    output: str


class ChatResponse(BaseModel):
    reply: str
    raw: Dict[str, Any] = Field(default_factory=dict)
    contexts: List[ContextSnippet] = Field(default_factory=list)
    tool_results: List[ToolExecutionResult] = Field(default_factory=list)


class DocumentItem(BaseModel):
    model_config = ConfigDict(from_attributes=True)

    id: str
    original_name: str
    file_size: int
    chunk_count: int
    created_at: datetime
    summary: Optional[str]


class ToolResponse(BaseModel):
    model_config = ConfigDict(from_attributes=True)

    id: str
    name: str
    description: str
    tool_type: str
    config: Dict[str, Any]
    is_active: bool
    created_at: datetime
    updated_at: datetime


class ToolCreateRequest(BaseModel):
    name: str
    description: str
    tool_type: Literal["builtin", "http_get"]
    config: Dict[str, Any] = Field(default_factory=dict)
    is_active: bool = True


class ToolUpdateRequest(BaseModel):
    name: Optional[str] = None
    description: Optional[str] = None
    tool_type: Optional[Literal["builtin", "http_get"]] = None
    config: Optional[Dict[str, Any]] = None
    is_active: Optional[bool] = None


class ToolExecuteRequest(BaseModel):
    arguments: Dict[str, Any] = Field(default_factory=dict)


class ToolExecuteResponse(BaseModel):
    tool_id: str
    tool_name: str
    output: str


class ToolLogItem(BaseModel):
    id: str
    tool_id: str
    tool_name: str
    arguments: Optional[Dict[str, Any]]
    result_preview: Optional[str]
    success: bool
    error_message: Optional[str]
    created_at: datetime



# ==================== Promptæ¨¡æ¿ç›¸å…³çš„è¯·æ±‚å’Œå“åº”æ¨¡å‹ ====================

class PromptTemplateResponse(BaseModel):
    """Promptæ¨¡æ¿å“åº”æ¨¡å‹"""
    model_config = ConfigDict(from_attributes=True)
    
    id: str
    name: str
    agent_id: str
    content: str
    description: Optional[str]
    is_default: bool
    is_active: bool
    created_at: datetime
    updated_at: datetime


class PromptTemplateCreateRequest(BaseModel):
    """åˆ›å»ºPromptæ¨¡æ¿çš„è¯·æ±‚æ¨¡å‹"""
    name: str
    agent_id: str
    content: str
    description: Optional[str] = None


class PromptTemplateUpdateRequest(BaseModel):
    """æ›´æ–°Promptæ¨¡æ¿çš„è¯·æ±‚æ¨¡å‹"""
    name: Optional[str] = None
    content: Optional[str] = None
    description: Optional[str] = None
    is_active: Optional[bool] = None


class PromptGenerateRequest(BaseModel):
    """Promptç”Ÿæˆè¯·æ±‚"""
    agent_id: str = Field(..., description="æ™ºèƒ½ä½“ID")
    user_requirement: str = Field(..., description="ç”¨æˆ·éœ€æ±‚æè¿°ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰")
    reference_style: Optional[str] = Field(None, description="å‚è€ƒé£æ ¼ï¼ˆå¦‚ï¼šç®€æ´ã€è¯¦ç»†ã€ä¸“ä¸šç­‰ï¼‰")
    output_format: Optional[str] = Field(None, description="æœŸæœ›çš„è¾“å‡ºæ ¼å¼ï¼ˆå¦‚ï¼šJSONã€Markdownã€çº¯æ–‡æœ¬ç­‰ï¼‰")
    keywords: Optional[List[str]] = Field(None, description="ç”¨æˆ·é€‰æ‹©çš„å…³é”®æŒ‡ä»¤æˆ–è¯æ±‡")


class ExtractKeywordsRequest(BaseModel):
    """å…³é”®è¯æå–è¯·æ±‚"""
    user_requirement: str = Field(..., description="ç”¨æˆ·éœ€æ±‚æè¿°")



def ensure_directories(settings: Settings) -> None:
    for path in (settings.data_dir, settings.chroma_dir, settings.sqlite_path.parent):
        Path(path).mkdir(parents=True, exist_ok=True)


def register_builtin_tools_on_startup() -> None:
    """
    åœ¨å¯åŠ¨æ—¶è‡ªåŠ¨æ³¨å†Œæ‰€æœ‰å†…ç½®å·¥å…·
    
    ä½œç”¨ï¼šç¡®ä¿æ•°æ®åº“ä¸­æœ‰å¯ç”¨çš„å†…ç½®å·¥å…·ï¼Œé¿å… Agent æ‰¾ä¸åˆ°å·¥å…·
    ç­–ç•¥ï¼šåªæ³¨å†Œæ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„å·¥å…·ï¼Œé¿å…é‡å¤æ³¨å†Œ
    """
    logger.info("ğŸ”§ [å¯åŠ¨] æ£€æŸ¥å¹¶æ³¨å†Œå†…ç½®å·¥å…·...")
    
    # è·å–æ•°æ®åº“ä¼šè¯
    SessionLocal = get_session_factory()
    session = SessionLocal()
    
    try:
        # å®šä¹‰éœ€è¦æ³¨å†Œçš„å†…ç½®å·¥å…·
        builtin_tools_to_register = [
            {
                "name": "å¤©æ°”æŸ¥è¯¢",
                "description": "æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”æƒ…å†µï¼ŒåŒ…æ‹¬æ¸©åº¦ã€æ¹¿åº¦ã€é£é€Ÿç­‰ä¿¡æ¯ã€‚æ”¯æŒä¸­è‹±æ–‡åŸå¸‚åã€‚",
                "builtin_key": "get_weather"
            },
            {
                "name": "ç½‘é¡µæœç´¢",
                "description": "åœ¨äº’è”ç½‘ä¸Šæœç´¢ä¿¡æ¯ã€‚è¾“å…¥æœç´¢å…³é”®è¯ï¼Œè¿”å›ç›¸å…³ç½‘é¡µçš„æ ‡é¢˜ã€é“¾æ¥å’Œæ‘˜è¦ã€‚é€‚åˆæŸ¥æ‰¾æœ€æ–°ä¿¡æ¯ã€æ–°é—»ã€æŠ€æœ¯æ–‡æ¡£ç­‰ã€‚",
                "builtin_key": "web_search"
            },
            {
                "name": "ç»˜åˆ¶æ€ç»´å¯¼å›¾",
                "description": "ä½¿ç”¨ Mermaid è¯­æ³•ç»˜åˆ¶æµç¨‹å›¾ã€æ€ç»´å¯¼å›¾ã€æ¶æ„å›¾ç­‰ç»“æ„å›¾ï¼Œä¿å­˜ä¸º Markdown æ–‡ä»¶ã€‚",
                "builtin_key": "draw_diagram"
            },
            {
                "name": "å†™å…¥ç¬”è®°",
                "description": "åœ¨ data/notes ç›®å½•ä¸‹åˆ›å»ºæˆ–è¦†ç›–ç¬”è®°æ–‡ä»¶ï¼Œå¯ç”¨äºè®°å½•æ€»ç»“æˆ–æ‰§è¡Œç»“æœã€‚",
                "builtin_key": "write_note"
            },
            {
                "name": "è·å–ç½‘é¡µå†…å®¹",
                "description": "è¯»å–æŒ‡å®šç½‘é¡µçš„å®Œæ•´å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰ã€‚é€‚åˆæ·±å…¥é˜…è¯»æŸä¸ªç½‘é¡µçš„è¯¦ç»†ä¿¡æ¯ã€‚",
                "builtin_key": "fetch_webpage"
            },
            {
                "name": "åˆ—å‡ºæ•°æ®åº“è¡¨",
                "description": "åˆ—å‡ºMySQLæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨åŠå…¶æè¿°ä¿¡æ¯ã€‚é€‚åˆåœ¨å¼€å§‹æŸ¥è¯¢å‰äº†è§£æ•°æ®åº“ç»“æ„ã€‚",
                "builtin_key": "mysql_list_tables"
            },
            {
                "name": "è·å–è¡¨ç»“æ„",
                "description": "è·å–æŒ‡å®šè¡¨çš„è¯¦ç»†ç»“æ„ä¿¡æ¯ï¼ŒåŒ…æ‹¬åˆ—å®šä¹‰ã€ä¸»é”®ã€å¤–é”®ã€ç´¢å¼•ç­‰ã€‚è¾“å…¥é€—å·åˆ†éš”çš„è¡¨ååˆ—è¡¨ã€‚",
                "builtin_key": "mysql_get_schema"
            },
            {
                "name": "æ‰§è¡ŒSQLæŸ¥è¯¢",
                "description": "æ‰§è¡ŒMySQL SELECTæŸ¥è¯¢å¹¶è¿”å›ç»“æœï¼ˆJSONæ ¼å¼ï¼‰ã€‚ä»…æ”¯æŒSELECTæŸ¥è¯¢ï¼Œé™åˆ¶è¿”å›100æ¡è®°å½•ã€‚é€‚åˆæ•°æ®æ£€ç´¢å’Œç»Ÿè®¡åˆ†æã€‚",
                "builtin_key": "mysql_query"
            },
            {
                "name": "éªŒè¯SQLè¯­æ³•",
                "description": "åœ¨æ‰§è¡Œå‰éªŒè¯SQLæŸ¥è¯¢çš„è¯­æ³•æ˜¯å¦æ­£ç¡®ã€‚å»ºè®®åœ¨æ‰§è¡Œå¤æ‚æŸ¥è¯¢å‰å…ˆéªŒè¯ã€‚",
                "builtin_key": "mysql_validate"
            },
        ]
        
        # è·å–æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„å·¥å…·
        existing_tools = session.query(ToolRecord).all()
        existing_builtin_keys = set()
        
        for tool in existing_tools:
            try:
                config = json.loads(tool.config or "{}")
                if tool.tool_type == "builtin":
                    builtin_key = config.get("builtin_key")
                    if builtin_key:
                        existing_builtin_keys.add(builtin_key)
            except:
                pass
        
        # æ³¨å†Œç¼ºå¤±çš„å·¥å…·
        registered_count = 0
        for tool_def in builtin_tools_to_register:
            builtin_key = tool_def["builtin_key"]
            
            if builtin_key in existing_builtin_keys:
                logger.debug(f"   â­ï¸  å·¥å…·å·²å­˜åœ¨: {tool_def['name']} ({builtin_key})")
                continue
            
            # åˆ›å»ºæ–°å·¥å…·è®°å½•
            new_tool = ToolRecord(
                id=uuid.uuid4().hex,
                name=tool_def["name"],
                description=tool_def["description"],
                tool_type="builtin",
                config=json.dumps({"builtin_key": builtin_key}, ensure_ascii=False),
                is_active=True,
            )
            session.add(new_tool)
            registered_count += 1
            logger.info(f"   âœ… å·²æ³¨å†Œå·¥å…·: {tool_def['name']} ({builtin_key})")
        
        if registered_count > 0:
            session.commit()
            logger.info(f"ğŸ‰ [å¯åŠ¨] æˆåŠŸæ³¨å†Œ {registered_count} ä¸ªæ–°çš„å†…ç½®å·¥å…·")
        else:
            logger.info(f"âœ… [å¯åŠ¨] æ‰€æœ‰å†…ç½®å·¥å…·å·²å­˜åœ¨ï¼Œæ— éœ€æ³¨å†Œ")
        
        # æ˜¾ç¤ºå½“å‰å¯ç”¨çš„å·¥å…·
        all_active_tools = session.query(ToolRecord).filter(ToolRecord.is_active == True).all()
        logger.info(f"ğŸ“Š [å¯åŠ¨] å½“å‰å¯ç”¨å·¥å…·æ•°é‡: {len(all_active_tools)}")
        for tool in all_active_tools:
            config = json.loads(tool.config or "{}")
            builtin_key = config.get("builtin_key", "N/A")
            logger.info(f"   â€¢ {tool.name} ({tool.tool_type}, key: {builtin_key})")
            
    except Exception as e:
        logger.error(f"âŒ [å¯åŠ¨] æ³¨å†Œå†…ç½®å·¥å…·å¤±è´¥: {e}", exc_info=True)
        session.rollback()
    finally:
        session.close()


@app.on_event("startup")
async def startup() -> None:
    try:
        settings = get_settings()
        logger.info("æ•°æ®ç›®å½•: %s", settings.data_dir)
        logger.info("æ•°æ®åº“è·¯å¾„: %s", settings.sqlite_path)
        logger.info("Chroma ç›®å½•: %s", settings.chroma_dir)
        
        # éªŒè¯ API Key
        if not settings.validate_api_key():
            logger.warning("âš ï¸ DeepSeek API Key æœªé…ç½®æˆ–æ— æ•ˆï¼")
            logger.warning("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY æˆ–åœ¨ backend/.env æ–‡ä»¶ä¸­é…ç½®")
            logger.warning("ç¤ºä¾‹: DEEPSEEK_API_KEY=sk-your-real-api-key")
        else:
            logger.info("âœ… DeepSeek API Key å·²é…ç½®")
        
        ensure_directories(settings)
        init_engine(settings.sqlite_path)
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        
        # è‡ªåŠ¨æ³¨å†Œå†…ç½®å·¥å…·
        register_builtin_tools_on_startup()
        
        # é¢„åŠ è½½åµŒå…¥æ¨¡å‹ï¼ˆé¿å…é¦–æ¬¡ä¸Šä¼ æ–‡ä»¶å¡ä½ï¼‰
        # æ³¨æ„ï¼šå·²æ³¨é‡Šæ‰ï¼Œå› ä¸ºæ¨¡å‹åŠ è½½å¯èƒ½å ç”¨å¤§é‡å†…å­˜ï¼Œå¯¼è‡´ç³»ç»Ÿé‡å¯
        # æ¨¡å‹ä¼šåœ¨é¦–æ¬¡ä½¿ç”¨æ—¶æŒ‰éœ€åŠ è½½
        # try:
        #     logger.info("ğŸ”„ é¢„åŠ è½½åµŒå…¥æ¨¡å‹...")
        #     from .rag_service import get_embeddings
        #     embeddings = get_embeddings()
        #     test_emb = embeddings.embed_query("é¢„çƒ­æµ‹è¯•")
        #     logger.info(f"âœ… åµŒå…¥æ¨¡å‹å·²åŠ è½½ (ç»´åº¦: {len(test_emb)})")
        # except Exception as e:
        #     logger.warning(f"âš ï¸ åµŒå…¥æ¨¡å‹é¢„åŠ è½½å¤±è´¥: {e}")
            
    except Exception as exc:  # pragma: no cover
        logger.exception("å¯åŠ¨åˆå§‹åŒ–å¤±è´¥: %s", exc)
        raise


def get_db_session() -> Generator[Session, None, None]:
    SessionLocal = get_session_factory()
    session = SessionLocal()
    try:
        yield session
    finally:
        session.close()


async def invoke_deepseek(
    *,
    messages: List[Dict[str, str]],
    settings: Settings,
    model: str,
    temperature: float,
    max_tokens: Optional[int],
) -> tuple[str, Dict[str, Any]]:
    payload: Dict[str, Any] = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "stream": False,
    }
    if max_tokens is not None:
        payload["max_tokens"] = max_tokens

    headers = {
        "Authorization": f"Bearer {settings.deepseek_api_key}",
        "Content-Type": "application/json",
    }
    endpoint = f"{settings.deepseek_base_url.rstrip('/')}/chat/completions"

    async with httpx.AsyncClient(timeout=httpx.Timeout(60.0)) as client:
        response = await client.post(endpoint, json=payload, headers=headers)

    if response.status_code != 200:
        logger.error(
            "DeepSeek API error %s: %s", response.status_code, response.text
        )
        raise HTTPException(
            status_code=502,
            detail=f"DeepSeek API error {response.status_code}",
        )

    data = response.json()
    try:
        reply = data["choices"][0]["message"]["content"]
    except (KeyError, IndexError) as error:
        logger.exception("Unexpected DeepSeek response: %s", data)
        raise HTTPException(
            status_code=502, detail="Unexpected DeepSeek response structure"
        ) from error
    return reply, data


def apply_rag_context(
    base_messages: List[Dict[str, str]],
    contexts: List[RetrievedContext],
) -> List[Dict[str, str]]:
    if not contexts:
        return base_messages

    context_parts: List[str] = []
    for idx, ctx in enumerate(contexts, start=1):
        doc_name = ctx.original_name or "æœªçŸ¥æ–‡æ¡£"
        context_parts.append(
            f"ã€æ–‡æ¡£ç‰‡æ®µ{idx}ã€‘\næ¥æºï¼š{doc_name}\nå†…å®¹ï¼š\n{ctx.content}\n"
        )
    context_text = "".join(context_parts)
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œç°åœ¨ç”¨æˆ·ä¸Šä¼ äº†ä¸€äº›æ–‡æ¡£åˆ°çŸ¥è¯†åº“ã€‚ä»¥ä¸‹æ˜¯ä¸é—®é¢˜æœ€ç›¸å…³çš„ç‰‡æ®µï¼Œ"
        "è¯·ç»“åˆå®ƒä»¬å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n"
        f"{context_text}\n"
        "ã€é‡è¦æç¤ºã€‘\n"
        "1. è¯·ç›´æ¥å¼•ç”¨ä¸Šè¿°å†…å®¹ä½œç­”ã€‚\n"
        "2. å†…å®¹è¶³ä»¥å›ç­”æ—¶è¯·è¯¦ç»†é˜è¿°ï¼›ä¸è¶³æ—¶è¯´æ˜ç¼ºå¤±ä¿¡æ¯ã€‚\n"
        "3. å¯æ ‡æ³¨ç‰‡æ®µæ¥æºï¼Œé¿å…ç¼–é€ ã€‚"
    )
    return base_messages[:-1] + [{"role": "system", "content": system_prompt}] + [
        base_messages[-1]
    ]


def select_tool_records(payload: ChatRequest, session: Session) -> List[ToolRecord]:
    if not payload.use_tools:
        return []
    available = list_tools(session, include_inactive=False)
    if not payload.tool_ids:
        return available
    tool_map = {tool.id: tool for tool in available}
    missing = [tool_id for tool_id in payload.tool_ids if tool_id not in tool_map]
    if missing:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°ä»¥ä¸‹å·¥å…·ï¼š{', '.join(missing)}")
    return [tool_map[tool_id] for tool_id in payload.tool_ids]


def prepare_agent_environment(
    payload: ChatRequest,
    settings: Settings,
    session: Session,
) -> tuple[
    List[Dict[str, str]],
    List[Dict[str, str]],
    List[RetrievedContext],
    List[ToolRecord],
]:
    base_messages = [message.model_dump() for message in payload.messages]
    if not base_messages:
        raise HTTPException(status_code=400, detail="messages ä¸èƒ½ä¸ºç©ºã€‚")

    retrieved_contexts: List[RetrievedContext] = []
    if payload.use_knowledge_base:
        query = payload.messages[-1].content
        retrieved_contexts = retrieve_context(
            query=query, settings=settings, top_k=payload.top_k
        )
        if retrieved_contexts:
            base_messages = apply_rag_context(base_messages, retrieved_contexts)

    tool_records = select_tool_records(payload, session)
    llm_messages = list(base_messages)
    if tool_records:
        tool_prompt = build_tool_prompt(tool_records)
        llm_messages = [{"role": "system", "content": tool_prompt}] + llm_messages

    return base_messages, llm_messages, retrieved_contexts, tool_records


def build_context_snippets(
    retrieved_contexts: List[RetrievedContext],
) -> List[ContextSnippet]:
    return [
        ContextSnippet(
            document_id=ctx.document_id,
            original_name=ctx.original_name,
            content=ctx.content[:500],
        )
        for ctx in retrieved_contexts
    ]


def format_sse(event: str, data: Dict[str, Any]) -> bytes:
    payload = json.dumps(data, ensure_ascii=False)
    return f"event: {event}\ndata: {payload}\n\n".encode("utf-8")


@app.get("/health")
async def health(settings: Settings = Depends(get_settings)) -> Dict[str, str]:
    _ = settings.deepseek_api_key
    return {"status": "ok"}


# ==================== è®¤è¯ç›¸å…³ API ====================

class UserRegister(BaseModel):
    """ç”¨æˆ·æ³¨å†Œè¯·æ±‚æ¨¡å‹"""
    username: str
    email: str
    password: str


class UserLogin(BaseModel):
    """ç”¨æˆ·ç™»å½•è¯·æ±‚æ¨¡å‹"""
    email: str
    password: str


class TokenResponse(BaseModel):
    """Token å“åº”æ¨¡å‹"""
    access_token: str
    refresh_token: str
    token_type: str = "bearer"
    user_id: str
    username: str


class RefreshTokenRequest(BaseModel):
    """åˆ·æ–° Token è¯·æ±‚æ¨¡å‹"""
    refresh_token: str


@app.post("/api/auth/register", response_model=TokenResponse)
async def register(
    user_data: UserRegister,
    session: Session = Depends(get_db_session)
):
    """ç”¨æˆ·æ³¨å†Œæ¥å£"""
    # æ£€æŸ¥é‚®ç®±æ˜¯å¦å·²è¢«æ³¨å†Œ
    existing_user = session.query(User).filter(User.email == user_data.email).first()
    if existing_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="é‚®ç®±å·²è¢«æ³¨å†Œ"
        )
    
    # æ£€æŸ¥ç”¨æˆ·åæ˜¯å¦å·²è¢«ä½¿ç”¨
    existing_username = session.query(User).filter(
        User.username == user_data.username
    ).first()
    if existing_username:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ç”¨æˆ·åå·²è¢«ä½¿ç”¨"
        )
    
    # éªŒè¯å¯†ç é•¿åº¦
    if len(user_data.password) < 8:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="å¯†ç è‡³å°‘éœ€è¦8ä½å­—ç¬¦"
        )
    
    # åŠ å¯†å¯†ç 
    hashed_password = get_password_hash(user_data.password)
    
    # åˆ›å»ºæ–°ç”¨æˆ·
    new_user = User(
        username=user_data.username,
        email=user_data.email,
        hashed_password=hashed_password
    )
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    session.add(new_user)
    session.commit()
    session.refresh(new_user)
    
    # ç”Ÿæˆ JWT token
    access_token = create_access_token(data={"sub": new_user.id})
    refresh_token = create_refresh_token(data={"sub": new_user.id})
    
    logger.info(f"âœ… æ–°ç”¨æˆ·æ³¨å†ŒæˆåŠŸ: {user_data.email}")
    
    return TokenResponse(
        access_token=access_token,
        refresh_token=refresh_token,
        user_id=new_user.id,
        username=new_user.username
    )


@app.post("/api/auth/login", response_model=TokenResponse)
async def login(
    user_data: UserLogin,
    session: Session = Depends(get_db_session)
):
    """ç”¨æˆ·ç™»å½•æ¥å£"""
    user = authenticate_user(session, user_data.email, user_data.password)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="é‚®ç®±æˆ–å¯†ç é”™è¯¯",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # æ›´æ–°æœ€åç™»å½•æ—¶é—´
    user.last_login = datetime.utcnow()
    session.commit()
    
    # ç”Ÿæˆ JWT token
    access_token = create_access_token(data={"sub": user.id})
    refresh_token = create_refresh_token(data={"sub": user.id})
    
    logger.info(f"âœ… ç”¨æˆ·ç™»å½•æˆåŠŸ: {user_data.email}")
    
    return TokenResponse(
        access_token=access_token,
        refresh_token=refresh_token,
        user_id=user.id,
        username=user.username
    )


@app.post("/api/auth/refresh")
async def refresh_token_endpoint(
    token_data: RefreshTokenRequest,
    session: Session = Depends(get_db_session)
):
    """åˆ·æ–° Access Token æ¥å£"""
    payload = verify_token(token_data.refresh_token)
    if payload.get("type") != "refresh":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ— æ•ˆçš„åˆ·æ–° token"
        )
    
    user_id = payload.get("sub")
    user = session.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ç”¨æˆ·ä¸å­˜åœ¨"
        )
    
    # ç”Ÿæˆæ–°çš„ access token
    new_access_token = create_access_token(data={"sub": user.id})
    
    return {
        "access_token": new_access_token,
        "token_type": "bearer"
    }


# å®šä¹‰ get_current_user ä¾èµ–ï¼ˆéœ€è¦åœ¨è¿™é‡Œå®šä¹‰ä»¥é¿å…å¾ªç¯å¯¼å…¥ï¼‰
from .auth import oauth2_scheme

async def get_current_user(
    token: str = Depends(oauth2_scheme),
    session: Session = Depends(get_db_session)
) -> User:
    """è·å–å½“å‰ç™»å½•ç”¨æˆ·ï¼ˆFastAPI ä¾èµ–æ³¨å…¥ï¼‰"""
    from .auth import verify_token
    
    payload = verify_token(token)
    user_id: str = payload.get("sub")
    
    if user_id is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="æ— æ•ˆçš„è®¤è¯å‡­æ®ï¼šç¼ºå°‘ç”¨æˆ·ID",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # ä»æ•°æ®åº“æŸ¥è¯¢ç”¨æˆ·
    user = session.query(User).filter(User.id == user_id).first()
    
    if user is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ç”¨æˆ·ä¸å­˜åœ¨",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¢«ç¦ç”¨
    if not user.is_active:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ç”¨æˆ·å·²è¢«ç¦ç”¨",
        )
    
    return user


@app.get("/api/auth/me")
async def get_me(current_user: User = Depends(get_current_user)):
    """è·å–å½“å‰ç™»å½•ç”¨æˆ·ä¿¡æ¯"""
    return {
        "id": current_user.id,
        "username": current_user.username,
        "email": current_user.email,
        "created_at": current_user.created_at,
        "last_login": current_user.last_login
    }


@app.post("/chat", response_model=ChatResponse)
async def chat(
    payload: ChatRequest,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> ChatResponse:
    _, llm_messages, retrieved_contexts, tool_records = prepare_agent_environment(
        payload, settings, session
    )

    first_reply, first_data = await invoke_deepseek(
        messages=llm_messages,
        settings=settings,
        model=payload.model,
        temperature=payload.temperature,
        max_tokens=payload.max_tokens,
    )

    tool_results: List[ToolExecutionResult] = []
    final_reply = first_reply
    raw_payload: Dict[str, Any] = {"first_call": first_data}

    if tool_records:
        tool_call = parse_tool_call(first_reply)
        if tool_call:
            tool_id = tool_call.get("tool_id")
            arguments = tool_call.get("arguments", {})
            if not tool_id:
                raise HTTPException(status_code=400, detail="tool_call ç¼ºå°‘ tool_idã€‚")
            matched_tool = next(
                (tool for tool in tool_records if tool.id == tool_id), None
            )
            if matched_tool is None:
                raise HTTPException(status_code=404, detail=f"å·¥å…· {tool_id} ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­")

            result_text = execute_tool(
                tool=matched_tool,
                arguments=arguments if isinstance(arguments, dict) else {},
                settings=settings,
                session=session,
            )
            result_item = ToolExecutionResult(
                tool_id=matched_tool.id,
                tool_name=matched_tool.name,
                output=result_text,
            )
            tool_results.append(result_item)

            followup_messages = llm_messages + [
                {"role": "assistant", "content": first_reply},
                {
                    "role": "system",
                    "content": (
                        f"å·¥å…· {matched_tool.name} (ID: {matched_tool.id}) å·²æ‰§è¡Œå®Œæˆï¼Œè¾“å‡ºå¦‚ä¸‹ï¼š\n"
                        f"{result_text}\nè¯·ç»“åˆè¯¥ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
                    ),
                },
            ]
            final_reply, second_data = await invoke_deepseek(
                messages=followup_messages,
                settings=settings,
                model=payload.model,
                temperature=payload.temperature,
                max_tokens=payload.max_tokens,
            )
            raw_payload["final"] = second_data
        else:
            raw_payload["final"] = first_data
    else:
        raw_payload["final"] = first_data

    contexts = build_context_snippets(retrieved_contexts)

    return ChatResponse(
        reply=final_reply,
        raw=raw_payload,
        contexts=contexts,
        tool_results=tool_results,
    )


@app.post("/chat/stream")
async def chat_stream(
    payload: ChatRequest,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> StreamingResponse:
    base_messages, llm_messages, retrieved_contexts, tool_records = (
        prepare_agent_environment(payload, settings, session)
    )
    contexts = build_context_snippets(retrieved_contexts)

    async def event_generator() -> AsyncGenerator[bytes, None]:
        try:
            yield format_sse("status", {"stage": "started"})
            yield format_sse(
                "context",
                {"items": [snippet.model_dump() for snippet in contexts]},
            )

            first_reply, first_data = await invoke_deepseek(
                messages=llm_messages,
                settings=settings,
                model=payload.model,
                temperature=payload.temperature,
                max_tokens=payload.max_tokens,
            )
            yield format_sse("assistant_draft", {"content": first_reply})

            tool_results: List[ToolExecutionResult] = []
            final_reply = first_reply
            raw_payload: Dict[str, Any] = {"first_call": first_data}

            if tool_records:
                tool_call = parse_tool_call(first_reply)
                if tool_call:
                    yield format_sse("tool_call", tool_call)
                    tool_id = tool_call.get("tool_id")
                    arguments = tool_call.get("arguments", {})
                    matched_tool = next(
                        (tool for tool in tool_records if tool.id == tool_id), None
                    )
                    if matched_tool is None:
                        raise HTTPException(
                            status_code=404,
                            detail=f"å·¥å…· {tool_id} ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­",
                        )
                    result_text = execute_tool(
                        tool=matched_tool,
                        arguments=arguments if isinstance(arguments, dict) else {},
                        settings=settings,
                        session=session,
                    )
                    result_item = ToolExecutionResult(
                        tool_id=matched_tool.id,
                        tool_name=matched_tool.name,
                        output=result_text,
                    )
                    tool_results.append(result_item)
                    yield format_sse(
                        "tool_result", result_item.model_dump()
                    )

                    followup_messages = llm_messages + [
                        {"role": "assistant", "content": first_reply},
                        {
                            "role": "system",
                            "content": (
                                f"å·¥å…· {matched_tool.name} (ID: {matched_tool.id}) å·²æ‰§è¡Œå®Œæˆï¼Œè¾“å‡ºå¦‚ä¸‹ï¼š\n"
                                f"{result_text}\nè¯·ç»“åˆè¯¥ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
                            ),
                        },
                    ]
                    final_reply, second_data = await invoke_deepseek(
                        messages=followup_messages,
                        settings=settings,
                        model=payload.model,
                        temperature=payload.temperature,
                        max_tokens=payload.max_tokens,
                    )
                    raw_payload["final"] = second_data
                    yield format_sse(
                        "assistant_final", {"content": final_reply}
                    )
                else:
                    # æ²¡æœ‰æ‰¾åˆ°å·¥å…·è°ƒç”¨ï¼Œfirst_reply å°±æ˜¯æœ€ç»ˆå›å¤
                    raw_payload["final"] = first_data
                    yield format_sse(
                        "assistant_final", {"content": first_reply}
                    )
            else:
                # æ²¡æœ‰å¯ç”¨å·¥å…·ï¼Œfirst_reply å°±æ˜¯æœ€ç»ˆå›å¤
                raw_payload["final"] = first_data
                yield format_sse(
                    "assistant_final", {"content": first_reply}
                )

            yield format_sse(
                "completed",
                {
                    "reply": final_reply,
                    "contexts": [snippet.model_dump() for snippet in contexts],
                    "tool_results": [result.model_dump() for result in tool_results],
                    "raw": raw_payload,
                },
            )
        except HTTPException as http_error:
            yield format_sse(
                "error",
                {"message": http_error.detail, "status_code": http_error.status_code},
            )
        except Exception as exc:  # pragma: no cover - streaming fallback
            logger.exception("Streaming chat å‡ºé”™: %s", exc)
            yield format_sse("error", {"message": str(exc)})

    return StreamingResponse(event_generator(), media_type="text/event-stream")


@app.post("/documents/upload", response_model=DocumentItem)
async def upload_document(
    file: UploadFile = File(...),
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> DocumentItem:
    record = await ingest_document(file, settings=settings, session=session)
    return DocumentItem.model_validate(record)


@app.get("/documents", response_model=List[DocumentItem])
async def list_uploaded_documents(
    session: Session = Depends(get_db_session),
) -> List[DocumentItem]:
    records = list_documents(session)
    return [DocumentItem.model_validate(record) for record in records]


@app.delete("/documents/{document_id}")
async def remove_document(
    document_id: str,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> Dict[str, str]:
    delete_document(document_id=document_id, settings=settings, session=session)
    return {"status": "deleted"}


@app.get("/tools/builtin-options")
async def get_builtin_options() -> List[Dict[str, Any]]:
    return list_builtin_options()


@app.get("/tools", response_model=List[ToolResponse])
async def list_registered_tools(
    include_inactive: bool = False,
    session: Session = Depends(get_db_session),
) -> List[ToolResponse]:
    records = list_tools(session, include_inactive=include_inactive)
    return [serialize_tool(record) for record in records]


@app.post("/tools", response_model=ToolResponse)
async def create_tool(
    payload: ToolCreateRequest,
    session: Session = Depends(get_db_session),
) -> ToolResponse:
    validate_tool_config(payload.tool_type, payload.config)
    tool = ToolRecord(
        id=uuid.uuid4().hex,
        name=payload.name,
        description=payload.description,
        tool_type=payload.tool_type,
        config=json.dumps(payload.config, ensure_ascii=False),
        is_active=payload.is_active,
    )
    session.add(tool)
    session.commit()
    session.refresh(tool)
    return serialize_tool(tool)


@app.put("/tools/{tool_id}", response_model=ToolResponse)
async def update_tool(
    tool_id: str,
    payload: ToolUpdateRequest,
    session: Session = Depends(get_db_session),
) -> ToolResponse:
    tool = get_tool_by_id(session, tool_id)
    if tool is None:
        raise HTTPException(status_code=404, detail="å·¥å…·ä¸å­˜åœ¨ã€‚")

    if payload.name is not None:
        tool.name = payload.name
    if payload.description is not None:
        tool.description = payload.description
    if payload.tool_type is not None:
        tool.tool_type = payload.tool_type
    if payload.config is not None:
        validate_tool_config(tool.tool_type, payload.config)
        tool.config = json.dumps(payload.config, ensure_ascii=False)
    if payload.is_active is not None:
        tool.is_active = payload.is_active

    session.commit()
    session.refresh(tool)
    return serialize_tool(tool)


@app.delete("/tools/{tool_id}")
async def delete_tool(
    tool_id: str,
    session: Session = Depends(get_db_session),
) -> Dict[str, str]:
    tool = get_tool_by_id(session, tool_id)
    if tool is None:
        raise HTTPException(status_code=404, detail="å·¥å…·ä¸å­˜åœ¨ã€‚")
    session.delete(tool)
    session.commit()
    return {"status": "deleted"}


@app.post("/tools/{tool_id}/execute", response_model=ToolExecuteResponse)
async def execute_tool_endpoint(
    tool_id: str,
    payload: ToolExecuteRequest,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> ToolExecuteResponse:
    tool = get_tool_by_id(session, tool_id)
    if tool is None:
        raise HTTPException(status_code=404, detail="å·¥å…·ä¸å­˜åœ¨ã€‚")

    result = execute_tool(
        tool=tool,
        arguments=payload.arguments,
        settings=settings,
        session=session,
    )
    return ToolExecuteResponse(tool_id=tool.id, tool_name=tool.name, output=result)


@app.get("/tool-logs", response_model=List[ToolLogItem])
async def get_tool_logs(
    limit: int = 50,
    session: Session = Depends(get_db_session),
) -> List[ToolLogItem]:
    logs = list_tool_logs(session, limit=limit)
    return [
        ToolLogItem(
            id=log.id,
            tool_id=log.tool_id,
            tool_name=log.tool_name,
            arguments=json.loads(log.arguments) if log.arguments else None,
            result_preview=log.result_preview,
            success=log.success,
            error_message=log.error_message,
            created_at=log.created_at,
        )
        for log in logs
    ]


@app.post("/chat/agent", response_model=ChatResponse)
async def chat_with_langgraph_agent(
    payload: ChatRequest,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> ChatResponse:
    """
    ä½¿ç”¨ LangGraph Agent å¤„ç†å¯¹è¯
    
    ç‰¹ç‚¹ï¼š
    - å¤šæ­¥éª¤è§„åˆ’ä¸æ‰§è¡Œ
    - æ™ºèƒ½å·¥å…·é€‰æ‹©
    - çŠ¶æ€æŒä¹…åŒ–
    - åæ€ä¸ä¼˜åŒ–
    - é•¿æœŸè®°å¿†ç³»ç»Ÿ
    """
    logger.info("ğŸ¤– [LangGraph Agent] å¼€å§‹å¤„ç†è¯·æ±‚")
    
    # è·å–å¯ç”¨å·¥å…·
    tool_records = select_tool_records(payload, session)
    
    # è¿è¡Œ LangGraph Agent
    result = await run_agent(
        user_query=payload.messages[-1].content if payload.messages else "",
        settings=settings,
        session=session,
        tool_records=tool_records,
        use_knowledge_base=payload.use_knowledge_base,
        conversation_history=[msg.model_dump() for msg in payload.messages],
        session_id=payload.session_id,
        user_id=payload.user_id,
    )
    
    # æ„å»ºå“åº”
    contexts = [
        ContextSnippet(
            document_id=ctx.get("document_id"),
            original_name=ctx.get("original_name"),
            content=ctx.get("content", "")[:500]
        )
        for ctx in result.get("retrieved_contexts", [])
    ]
    
    tool_results = [
        ToolExecutionResult(
            tool_id=tr.get("tool_id", ""),
            tool_name=tr.get("tool_name", ""),
            output=tr.get("output", "")
        )
        for tr in result.get("tool_results", [])
    ]
    
    return ChatResponse(
        reply=result.get("final_answer", "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆç­”æ¡ˆ"),
        raw={
            "thoughts": result.get("thoughts", []),
            "observations": result.get("observations", []),
            "plan": result.get("plan", ""),
            "quality_score": result.get("quality_score", 0.0),
            "reflection": result.get("reflection", ""),
            "thread_id": result.get("thread_id", ""),
            "success": result.get("success", False),
        },
        contexts=contexts,
        tool_results=tool_results,
    )


@app.get("/agent/workflow/visualization")
async def get_workflow_visualization() -> Dict[str, Any]:
    """
    è·å– LangGraph Agent å·¥ä½œæµçš„å¯è§†åŒ–è¡¨ç¤ºï¼ˆMermaid æ ¼å¼ï¼‰
    """
    mermaid_graph = """
graph TD
    A[ç”¨æˆ·è¾“å…¥] --> B[ğŸ§  è§„åˆ’å™¨<br/>ä»»åŠ¡åˆ†æä¸è§„åˆ’]
    B --> C[ğŸ”€ è·¯ç”±å™¨<br/>å†³ç­–ä¸‹ä¸€æ­¥]
    
    C -->|éœ€è¦çŸ¥è¯†åº“| D[ğŸ“š çŸ¥è¯†åº“æ£€ç´¢<br/>RAGæ£€ç´¢]
    C -->|éœ€è¦å·¥å…·| E[ğŸ”§ å·¥å…·æ‰§è¡Œå™¨<br/>è°ƒç”¨å·¥å…·]
    C -->|ä¿¡æ¯å……è¶³| F[ğŸ¤” åæ€å™¨<br/>è´¨é‡è¯„ä¼°]
    
    D --> C
    E --> C
    
    F -->|è´¨é‡ä¸è¶³<br/>éœ€è¦äººå·¥| G[ğŸ‘¤ äººå·¥ä»‹å…¥<br/>ç­‰å¾…åé¦ˆ]
    F -->|è´¨é‡åˆæ ¼| H[âœ¨ åˆæˆå™¨<br/>ç”Ÿæˆç­”æ¡ˆ]
    
    G --> C
    
    H --> I[å®Œæˆ]
    
    style A fill:#667eea,stroke:#333,stroke-width:2px,color:#fff
    style I fill:#10a37f,stroke:#333,stroke-width:2px,color:#fff
    style B fill:#fff9e6,stroke:#ffc107,stroke-width:2px
    style C fill:#e6f7ff,stroke:#1890ff,stroke-width:2px
    style D fill:#f0f9ff,stroke:#10a37f,stroke-width:2px
    style E fill:#f0f9ff,stroke:#10a37f,stroke-width:2px
    style F fill:#fff0f6,stroke:#eb2f96,stroke-width:2px
    style G fill:#fff1f0,stroke:#ff4d4f,stroke-width:2px
    style H fill:#f6ffed,stroke:#52c41a,stroke-width:2px
"""
    
    return {
        "mermaid_code": mermaid_graph,
        "description": "LangGraph Agent å·¥ä½œæµå›¾",
        "nodes": [
            {"id": "planner", "name": "è§„åˆ’å™¨", "description": "åˆ†æç”¨æˆ·é—®é¢˜ï¼Œåˆ¶å®šæ‰§è¡Œè®¡åˆ’"},
            {"id": "router", "name": "è·¯ç”±å™¨", "description": "æ ¹æ®å½“å‰çŠ¶æ€å†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œ"},
            {"id": "knowledge_search", "name": "çŸ¥è¯†åº“æ£€ç´¢", "description": "ä»å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³å†…å®¹"},
            {"id": "tool_executor", "name": "å·¥å…·æ‰§è¡Œå™¨", "description": "æ™ºèƒ½é€‰æ‹©å¹¶æ‰§è¡Œå·¥å…·"},
            {"id": "reflector", "name": "åæ€å™¨", "description": "è¯„ä¼°å½“å‰è¿›å±•ï¼Œå†³å®šæ˜¯å¦éœ€è¦è°ƒæ•´"},
            {"id": "synthesizer", "name": "åˆæˆå™¨", "description": "ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"},
            {"id": "human_input", "name": "äººå·¥ä»‹å…¥", "description": "æš‚åœæ‰§è¡Œï¼Œç­‰å¾…äººå·¥åé¦ˆ"}
        ]
    }


@app.post("/chat/agent/stream")
async def chat_with_langgraph_agent_stream(
    payload: ChatRequest,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> StreamingResponse:
    """
    ä½¿ç”¨ LangGraph Agent å¤„ç†å¯¹è¯ï¼ˆæµå¼ï¼‰
    
    å®æ—¶è¿”å› Agent çš„æ€è€ƒè¿‡ç¨‹å’Œæ‰§è¡Œæ­¥éª¤
    """
    logger.info("ğŸŒŠ [LangGraph Agent Stream] å¼€å§‹æµå¼å¤„ç†")
    
    tool_records = select_tool_records(payload, session)
    
    # è·å–æˆ–ç”Ÿæˆ session_id
    session_id = payload.session_id or str(uuid.uuid4())
    
    async def event_generator() -> AsyncGenerator[bytes, None]:
        try:
            # å‘é€çŠ¶æ€äº‹ä»¶ï¼ŒåŒ…å« session_id ä»¥ä¾¿å‰ç«¯ä¿å­˜
            yield format_sse("status", {
                "stage": "started", 
                "mode": "langgraph_agent",
                "session_id": session_id
            })
            
            # æµå¼æ‰§è¡Œ LangGraph Agent
            async for event in stream_agent(
                user_query=payload.messages[-1].content if payload.messages else "",
                settings=settings,
                session=session,
                tool_records=tool_records,
                use_knowledge_base=payload.use_knowledge_base,
                conversation_history=[msg.model_dump() for msg in payload.messages],
                session_id=session_id,
                user_id=payload.user_id,
            ):
                event_type = event.get("event", "unknown")
                
                if event_type == "node_output":
                    # èŠ‚ç‚¹æ‰§è¡Œè¾“å‡º
                    node_name = event.get("node", "")
                    node_data = event.get("data", {})
                    
                    # å‘é€èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
                    yield format_sse("agent_node", {
                        "node": node_name,
                        "status": "completed",
                        "data": node_data,
                        "timestamp": event.get("timestamp")
                    })
                    
                    # å¦‚æœæœ‰æ€è€ƒè¿‡ç¨‹ï¼Œå‘é€æ€è€ƒäº‹ä»¶
                    if "thoughts" in node_data and node_data["thoughts"]:
                        for thought in node_data["thoughts"]:
                            yield format_sse("agent_thought", {
                                "node": node_name,
                                "thought": thought,
                                "timestamp": event.get("timestamp")
                            })
                    
                    # å¦‚æœæœ‰è§‚å¯Ÿç»“æœï¼Œå‘é€è§‚å¯Ÿäº‹ä»¶
                    if "observations" in node_data and node_data["observations"]:
                        for observation in node_data["observations"]:
                            yield format_sse("agent_observation", {
                                "node": node_name,
                                "observation": observation,
                                "timestamp": event.get("timestamp")
                            })
                    
                    # å¦‚æœæœ‰å·¥å…·ç»“æœï¼Œå‘é€å·¥å…·äº‹ä»¶
                    if "tool_results" in node_data and node_data["tool_results"]:
                        for tool_result in node_data["tool_results"]:
                            yield format_sse("tool_result", tool_result)
                    
                    # å¦‚æœæœ‰çŸ¥è¯†åº“æ£€ç´¢ç»“æœ
                    if "retrieved_contexts" in node_data and node_data["retrieved_contexts"]:
                        yield format_sse("context", {
                            "items": node_data["retrieved_contexts"]
                        })
                    
                    # å¦‚æœæœ‰æœ€ç»ˆç­”æ¡ˆ
                    if "final_answer" in node_data and node_data["final_answer"]:
                        yield format_sse("assistant_final", {
                            "content": node_data["final_answer"]
                        })
                        logger.info(f"ğŸ“¤ å·²å‘é€æœ€ç»ˆç­”æ¡ˆåˆ°å‰ç«¯ï¼Œé•¿åº¦: {len(node_data['final_answer'])}")
                
                elif event_type == "token":
                    # å®æ—¶ Token æµ
                    yield format_sse("token", {"data": event.get("data", "")})
                
                elif event_type == "completed":
                    # Agent æ‰§è¡Œå®Œæˆ
                    yield format_sse("completed", {
                        "thread_id": event.get("thread_id"),
                        "timestamp": event.get("timestamp")
                    })
                    logger.info(f"ğŸ“¤ å·²å‘é€å®Œæˆäº‹ä»¶åˆ°å‰ç«¯")
        
        except HTTPException as http_error:
            yield format_sse(
                "error",
                {"message": http_error.detail, "status_code": http_error.status_code},
            )
        except Exception as exc:
            logger.exception("LangGraph Agent streaming å‡ºé”™: %s", exc)
            yield format_sse("error", {"message": str(exc)})
    
    return StreamingResponse(event_generator(), media_type="text/event-stream")


def serialize_tool(record: ToolRecord) -> ToolResponse:
    config = load_tool_config(record)
    return ToolResponse.model_validate(
        {
            "id": record.id,
            "name": record.name,
            "description": record.description,
            "tool_type": record.tool_type,
            "config": config,
            "is_active": record.is_active,
            "created_at": record.created_at,
            "updated_at": record.updated_at,
        }
    )


# ==================== Agentæ„å»ºå™¨API ====================


# ==================== Promptæ¨¡æ¿ç®¡ç†API ====================

@app.get("/prompts", response_model=List[PromptTemplateResponse])
async def list_prompt_templates_endpoint(
    agent_id: Optional[str] = None,
    include_inactive: bool = False,
    session: Session = Depends(get_db_session),
) -> List[PromptTemplateResponse]:
    """åˆ—å‡ºæ‰€æœ‰Promptæ¨¡æ¿ï¼ˆå¯æŒ‰æ™ºèƒ½ä½“ç­›é€‰ï¼‰"""
    templates = list_prompt_templates(
        session, 
        agent_id=agent_id, 
        include_inactive=include_inactive
    )
    return [
        PromptTemplateResponse.model_validate({
            "id": template.id,
            "name": template.name,
            "agent_id": template.agent_id,
            "content": template.content,
            "description": template.description,
            "is_default": template.is_default,
            "is_active": template.is_active,
            "created_at": template.created_at,
            "updated_at": template.updated_at,
        })
        for template in templates
    ]


@app.get("/prompts/{template_id}", response_model=PromptTemplateResponse)
async def get_prompt_template(
    template_id: str,
    session: Session = Depends(get_db_session),
) -> PromptTemplateResponse:
    """è·å–å•ä¸ªPromptæ¨¡æ¿"""
    template = get_prompt_template_by_id(session, template_id)
    if template is None:
        raise HTTPException(status_code=404, detail="Promptæ¨¡æ¿ä¸å­˜åœ¨")
    
    return PromptTemplateResponse.model_validate({
        "id": template.id,
        "name": template.name,
        "agent_id": template.agent_id,
        "content": template.content,
        "description": template.description,
        "is_default": template.is_default,
        "is_active": template.is_active,
        "created_at": template.created_at,
        "updated_at": template.updated_at,
    })


@app.get("/prompts/agent/{agent_id}", response_model=List[PromptTemplateResponse])
async def get_prompts_by_agent(
    agent_id: str,
    include_inactive: bool = False,
    session: Session = Depends(get_db_session),
) -> List[PromptTemplateResponse]:
    """è·å–æŒ‡å®šæ™ºèƒ½ä½“çš„æ‰€æœ‰Promptæ¨¡æ¿"""
    templates = list_prompt_templates(
        session, 
        agent_id=agent_id, 
        include_inactive=include_inactive
    )
    return [
        PromptTemplateResponse.model_validate({
            "id": template.id,
            "name": template.name,
            "agent_id": template.agent_id,
            "content": template.content,
            "description": template.description,
            "is_default": template.is_default,
            "is_active": template.is_active,
            "created_at": template.created_at,
            "updated_at": template.updated_at,
        })
        for template in templates
    ]


@app.get("/prompts/agent/{agent_id}/active", response_model=PromptTemplateResponse)
async def get_active_prompt_for_agent_endpoint(
    agent_id: str,
    session: Session = Depends(get_db_session),
) -> PromptTemplateResponse:
    """è·å–æŒ‡å®šæ™ºèƒ½ä½“å½“å‰æ¿€æ´»çš„Promptæ¨¡æ¿"""
    template = get_active_prompt_for_agent(session, agent_id)
    if template is None:
        raise HTTPException(
            status_code=404, 
            detail=f"æ™ºèƒ½ä½“ {agent_id} æ²¡æœ‰æ¿€æ´»çš„Promptæ¨¡æ¿"
        )
    
    return PromptTemplateResponse.model_validate({
        "id": template.id,
        "name": template.name,
        "agent_id": template.agent_id,
        "content": template.content,
        "description": template.description,
        "is_default": template.is_default,
        "is_active": template.is_active,
        "created_at": template.created_at,
        "updated_at": template.updated_at,
    })


@app.post("/prompts", response_model=PromptTemplateResponse)
async def create_prompt_template_endpoint(
    payload: PromptTemplateCreateRequest,
    session: Session = Depends(get_db_session),
) -> PromptTemplateResponse:
    """åˆ›å»ºæ–°çš„Promptæ¨¡æ¿"""
    template = create_prompt_template(
        session=session,
        name=payload.name,
        agent_id=payload.agent_id,
        content=payload.content,
        description=payload.description,
        is_default=False,  # ç”¨æˆ·åˆ›å»ºçš„æ¨¡æ¿ä¸æ˜¯é»˜è®¤æ¨¡æ¿
    )
    
    return PromptTemplateResponse.model_validate({
        "id": template.id,
        "name": template.name,
        "agent_id": template.agent_id,
        "content": template.content,
        "description": template.description,
        "is_default": template.is_default,
        "is_active": template.is_active,
        "created_at": template.created_at,
        "updated_at": template.updated_at,
    })


@app.put("/prompts/{template_id}", response_model=PromptTemplateResponse)
async def update_prompt_template_endpoint(
    template_id: str,
    payload: PromptTemplateUpdateRequest,
    session: Session = Depends(get_db_session),
) -> PromptTemplateResponse:
    """æ›´æ–°Promptæ¨¡æ¿"""
    template = update_prompt_template(
        session=session,
        template_id=template_id,
        name=payload.name,
        content=payload.content,
        description=payload.description,
        is_active=payload.is_active,
    )
    
    if template is None:
        raise HTTPException(status_code=404, detail="Promptæ¨¡æ¿ä¸å­˜åœ¨")
    
    return PromptTemplateResponse.model_validate({
        "id": template.id,
        "name": template.name,
        "agent_id": template.agent_id,
        "content": template.content,
        "description": template.description,
        "is_default": template.is_default,
        "is_active": template.is_active,
        "created_at": template.created_at,
        "updated_at": template.updated_at,
    })


@app.post("/prompts/{template_id}/activate", response_model=PromptTemplateResponse)
async def activate_prompt_template_endpoint(
    template_id: str,
    session: Session = Depends(get_db_session),
) -> PromptTemplateResponse:
    """æ¿€æ´»æŒ‡å®šçš„Promptæ¨¡æ¿ï¼ˆåŒæ—¶å°†åŒä¸€æ™ºèƒ½ä½“çš„å…¶ä»–æ¨¡æ¿è®¾ä¸ºéæ¿€æ´»ï¼‰"""
    template = get_prompt_template_by_id(session, template_id)
    if template is None:
        raise HTTPException(status_code=404, detail="Promptæ¨¡æ¿ä¸å­˜åœ¨")
    
    activated_template = activate_prompt_template(
        session=session,
        template_id=template_id,
        agent_id=template.agent_id,
    )
    
    if activated_template is None:
        raise HTTPException(
            status_code=400, 
            detail="æ— æ³•æ¿€æ´»è¯¥æ¨¡æ¿ï¼Œè¯·æ£€æŸ¥æ¨¡æ¿IDå’Œæ™ºèƒ½ä½“IDæ˜¯å¦åŒ¹é…"
        )
    
    return PromptTemplateResponse.model_validate({
        "id": activated_template.id,
        "name": activated_template.name,
        "agent_id": activated_template.agent_id,
        "content": activated_template.content,
        "description": activated_template.description,
        "is_default": activated_template.is_default,
        "is_active": activated_template.is_active,
        "created_at": activated_template.created_at,
        "updated_at": activated_template.updated_at,
    })


@app.post("/prompts/{template_id}/deactivate", response_model=PromptTemplateResponse)
async def deactivate_prompt_template_endpoint(
    template_id: str,
    session: Session = Depends(get_db_session),
) -> PromptTemplateResponse:
    """åœç”¨æŒ‡å®šçš„Promptæ¨¡æ¿"""
    from .database import list_prompt_templates
    
    template = get_prompt_template_by_id(session, template_id)
    if template is None:
        raise HTTPException(status_code=404, detail="Promptæ¨¡æ¿ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–æ¿€æ´»çš„æ¨¡æ¿ï¼ˆé™¤äº†å½“å‰è¦åœç”¨çš„ï¼‰
    all_templates = list_prompt_templates(
        session, 
        agent_id=template.agent_id, 
        include_inactive=True
    )
    other_active_templates = [
        t for t in all_templates 
        if t.id != template_id and t.is_active
    ]
    
    # å¦‚æœåœç”¨é»˜è®¤æ¨¡æ¿ï¼Œéœ€è¦ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå…¶ä»–æ¿€æ´»çš„æ¨¡æ¿
    if template.is_default:
        if not other_active_templates:
            raise HTTPException(
                status_code=400,
                detail="ä¸èƒ½åœç”¨é»˜è®¤æ¨¡æ¿ï¼šè¯¥æ™ºèƒ½ä½“æ²¡æœ‰å…¶ä»–æ¿€æ´»çš„æ¨¡æ¿ã€‚è¯·å…ˆæ¿€æ´»å¦ä¸€ä¸ªæ¨¡æ¿ï¼Œæˆ–åˆ›å»ºæ–°æ¨¡æ¿åå†åœç”¨é»˜è®¤æ¨¡æ¿ã€‚"
            )
    
    # ä½¿ç”¨æ›´æ–°æ¥å£åœç”¨
    updated_template = update_prompt_template(
        session=session,
        template_id=template_id,
        name=None,
        content=None,
        description=None,
        is_active=False,
    )
    
    if updated_template is None:
        raise HTTPException(status_code=404, detail="Promptæ¨¡æ¿ä¸å­˜åœ¨")
    
    return PromptTemplateResponse.model_validate({
        "id": updated_template.id,
        "name": updated_template.name,
        "agent_id": updated_template.agent_id,
        "content": updated_template.content,
        "description": updated_template.description,
        "is_default": updated_template.is_default,
        "is_active": updated_template.is_active,
        "created_at": updated_template.created_at,
        "updated_at": updated_template.updated_at,
    })


@app.delete("/prompts/{template_id}")
async def delete_prompt_template_endpoint(
    template_id: str,
    session: Session = Depends(get_db_session),
) -> Dict[str, str]:
    """åˆ é™¤Promptæ¨¡æ¿ï¼ˆä¸èƒ½åˆ é™¤é»˜è®¤æ¨¡æ¿ï¼‰"""
    success = delete_prompt_template(session, template_id)
    if not success:
        template = get_prompt_template_by_id(session, template_id)
        if template is None:
            raise HTTPException(status_code=404, detail="Promptæ¨¡æ¿ä¸å­˜åœ¨")
        if template.is_default:
            raise HTTPException(
                status_code=400, 
                detail="ä¸èƒ½åˆ é™¤é»˜è®¤æ¨¡æ¿ï¼Œé»˜è®¤æ¨¡æ¿æ˜¯ç³»ç»Ÿé¢„è®¾çš„"
            )
        raise HTTPException(status_code=400, detail="åˆ é™¤å¤±è´¥")
    
    return {"status": "deleted", "message": "Promptæ¨¡æ¿å·²åˆ é™¤"}


@app.post("/prompts/init-defaults")
async def init_default_prompts(
    session: Session = Depends(get_db_session),
) -> Dict[str, Any]:
    """åˆå§‹åŒ–é»˜è®¤Promptæ¨¡æ¿ï¼ˆå°†ç¡¬ç¼–ç çš„promptä¿å­˜åˆ°æ•°æ®åº“ä½œä¸ºç¤ºä¾‹ï¼‰"""
    from .agent_roles import get_default_prompts
    from .database import list_prompt_templates
    
    default_prompts = get_default_prompts()
    created_count = 0
    skipped_count = 0
    
    for prompt_data in default_prompts:
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥æ™ºèƒ½ä½“çš„é»˜è®¤æ¨¡æ¿
        existing_templates = list_prompt_templates(
            session, 
            agent_id=prompt_data["agent_id"], 
            include_inactive=True
        )
        has_default = any(t.is_default for t in existing_templates)
        
        if has_default:
            skipped_count += 1
            continue
        
        # åˆ›å»ºé»˜è®¤æ¨¡æ¿
        create_prompt_template(
            session=session,
            name=prompt_data["name"],
            agent_id=prompt_data["agent_id"],
            content=prompt_data["content"],
            description=prompt_data.get("description", "ç³»ç»Ÿé»˜è®¤æ¨¡æ¿ï¼Œä½œä¸ºç¤ºä¾‹å‚è€ƒ"),
            is_default=True,  # æ ‡è®°ä¸ºé»˜è®¤æ¨¡æ¿
        )
        created_count += 1
    
    return {
        "status": "success",
        "created": created_count,
        "skipped": skipped_count,
        "message": f"åˆå§‹åŒ–å®Œæˆï¼šåˆ›å»º {created_count} ä¸ªé»˜è®¤æ¨¡æ¿ï¼Œè·³è¿‡ {skipped_count} ä¸ªå·²å­˜åœ¨çš„æ¨¡æ¿"
    }


def validate_prompt_template(
    prompt: str,
    agent_id: str,
    available_placeholders: List[str],
    format_requirements: Dict[str, Any],
) -> Dict[str, Any]:
    """
    éªŒè¯promptæ¨¡æ¿
    
    Args:
        prompt: å¾…éªŒè¯çš„prompt
        agent_id: æ™ºèƒ½ä½“ID
        available_placeholders: å¯ç”¨çš„å ä½ç¬¦åˆ—è¡¨
        format_requirements: æ ¼å¼è¦æ±‚
    
    Returns:
        éªŒè¯ç»“æœ
    """
    import re
    
    issues = []
    warnings = []
    
    # 1. æ£€æŸ¥å ä½ç¬¦
    placeholders = re.findall(r'\{(\w+)\}', prompt)
    if placeholders:
        # æ£€æŸ¥æœªå®šä¹‰çš„å ä½ç¬¦
        undefined = [p for p in placeholders if p not in available_placeholders]
        if undefined:
            warnings.append(f"ä½¿ç”¨äº†æœªå®šä¹‰çš„å ä½ç¬¦: {undefined}ï¼Œè¿™äº›å ä½ç¬¦å¯èƒ½ä¸ä¼šè¢«æ­£ç¡®æ›¿æ¢")
    
    # 2. æ£€æŸ¥æ ¼å¼è¦æ±‚
    if format_requirements:
        required_format = format_requirements.get("required_format")
        
        if required_format == "JSON":
            # æ£€æŸ¥æ˜¯å¦åŒ…å«JSONæ ¼å¼è¦æ±‚
            if "JSON" not in prompt.upper() and "json" not in prompt.lower():
                issues.append("ç¼ºå°‘JSONæ ¼å¼è¦æ±‚ï¼Œåˆ†æä¸“å®¶/éªŒè¯ä¸“å®¶å¿…é¡»è¿”å›JSONæ ¼å¼")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«"åªè¿”å› JSON"çš„å¼ºè°ƒ
            if "åªè¿”å›" not in prompt and "åªè¾“å‡º" not in prompt:
                warnings.append("å»ºè®®åœ¨promptæœ«å°¾æ·»åŠ 'åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚'çš„å¼ºè°ƒ")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«JSONç»“æ„è¯´æ˜
            required_fields = format_requirements.get("required_fields", [])
            missing_fields = []
            for field in required_fields[:3]:  # åªæ£€æŸ¥å‰3ä¸ªå­—æ®µä½œä¸ºç¤ºä¾‹
                if field not in prompt:
                    missing_fields.append(field)
            
            if missing_fields and len(missing_fields) == 3:
                warnings.append(f"å»ºè®®åœ¨promptä¸­æ˜ç¡®è¯´æ˜JSONç»“æ„ï¼ŒåŒ…å«å­—æ®µï¼š{', '.join(required_fields[:5])}...")
        
        elif required_format == "Markdown":
            if "Markdown" not in prompt and "markdown" not in prompt.lower():
                warnings.append("å»ºè®®æ˜ç¡®è¦æ±‚Markdownæ ¼å¼è¾“å‡º")
    
    # 3. æ£€æŸ¥å ä½ç¬¦æ ¼å¼ï¼ˆåŒèŠ±æ‹¬å·ï¼‰
    double_braces = re.findall(r'\{\{(\w+)\}\}', prompt)
    if double_braces:
        warnings.append(f"å‘ç°åŒèŠ±æ‹¬å·å ä½ç¬¦: {double_braces}ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è½¬æ¢ä¸ºå•èŠ±æ‹¬å·ï¼Œä½†å»ºè®®ç›´æ¥ä½¿ç”¨å•èŠ±æ‹¬å·")
    
    return {
        "valid": len(issues) == 0,
        "issues": issues,
        "warnings": warnings,
        "placeholders_found": list(set(placeholders)),
        "placeholders_available": available_placeholders,
    }


@app.post("/prompts/generate")
async def generate_prompt_from_requirement(
    payload: PromptGenerateRequest,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> Dict[str, Any]:
    """
    æ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªåŠ¨ç”ŸæˆPromptæ¨¡æ¿
    
    ç”¨æˆ·åªéœ€ç”¨è‡ªç„¶è¯­è¨€æè¿°éœ€æ±‚ï¼Œç³»ç»Ÿä¼šä½¿ç”¨LLMç”Ÿæˆç»“æ„åŒ–çš„prompt
    """
    from .graph_agent import invoke_llm
    from .agent_roles import list_available_agents
    
    # è·å–æ™ºèƒ½ä½“ä¿¡æ¯
    agents = list_available_agents()
    agent_info = next((a for a in agents if a["id"] == payload.agent_id), None)
    
    if not agent_info:
        raise HTTPException(status_code=404, detail=f"æ™ºèƒ½ä½“ {payload.agent_id} ä¸å­˜åœ¨")
    
    # æ„å»ºç”Ÿæˆpromptçš„æç¤ºè¯
    style_note = f"\n- å‚è€ƒé£æ ¼ï¼š{payload.reference_style}" if payload.reference_style else ""
    format_note = f"\n- è¾“å‡ºæ ¼å¼ï¼š{payload.output_format}" if payload.output_format else ""
    
    # æ ¹æ®æ™ºèƒ½ä½“ç±»å‹ç¡®å®šå¯ç”¨å ä½ç¬¦å’Œæ ¼å¼è¦æ±‚
    agent_placeholders = {
        "retrieval_specialist": ["user_query"],
        "analysis_specialist": ["user_query", "task_description", "analysis_context"],
        "summarization_specialist": ["user_query", "task_description", "full_context"],
        "verification_specialist": ["user_query", "task_description", "final_answer"],
    }
    
    format_requirements = {
        "analysis_specialist": {
            "required_format": "JSON",
            "required_fields": [
                "core_concepts", "key_facts", "key_data",
                "technical_principles", "relationships",
                "trends_insights", "critical_notes",
                "analysis_summary", "confidence_score"
            ],
            "json_structure": """{
  "core_concepts": [{"concept": "...", "explanation": "...", "importance": "high|medium|low"}],
  "key_facts": [{"fact": "...", "source": "...", "confidence": "high|medium|low"}],
  "key_data": [{"data_point": "...", "value": "...", "context": "..."}],
  "technical_principles": [{"principle": "...", "explanation": "...", "advantages": [], "limitations": []}],
  "relationships": [{"from": "...", "to": "...", "relationship_type": "...", "description": "..."}],
  "trends_insights": [{"trend": "...", "evidence": "...", "implications": "..."}],
  "critical_notes": [{"note_type": "...", "description": "..."}],
  "analysis_summary": "...",
  "confidence_score": 0.0-1.0
}"""
        },
        "verification_specialist": {
            "required_format": "JSON",
            "required_fields": [
                "accuracy_score", "completeness_score", "clarity_score",
                "relevance_score", "overall_score", "issues", "suggestions", "verdict"
            ],
            "json_structure": """{
  "accuracy_score": 0-10,
  "completeness_score": 0-10,
  "clarity_score": 0-10,
  "relevance_score": 0-10,
  "overall_score": 0-10,
  "issues": ["..."],
  "suggestions": ["..."],
  "verdict": "é€šè¿‡" æˆ– "éœ€è¦æ”¹è¿›"
}"""
        },
        "summarization_specialist": {
            "required_format": "Markdown",
            "note": "è¿”å›Markdownæ ¼å¼çš„æ–‡æœ¬æŠ¥å‘Šï¼Œä¸éœ€è¦JSON"
        }
    }
    
    available_placeholders = agent_placeholders.get(payload.agent_id, ["user_query", "task_description"])
    format_req = format_requirements.get(payload.agent_id, {})
    
    # å ä½ç¬¦æè¿°æ˜ å°„
    placeholder_descriptions = {
        "user_query": "ç”¨æˆ·æŸ¥è¯¢å†…å®¹",
        "task_description": "å½“å‰ä»»åŠ¡æè¿°",
        "analysis_context": "åˆ†æä¸Šä¸‹æ–‡ï¼ˆæ£€ç´¢ç»“æœã€å¾…åˆ†æå†…å®¹ï¼‰",
        "full_context": "å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆæ‰€æœ‰æ™ºèƒ½ä½“çš„ç»“æœæ±‡æ€»ï¼‰",
        "final_answer": "æœ€ç»ˆç­”æ¡ˆï¼ˆç”¨äºéªŒè¯ï¼‰",
    }
    
    # æ„å»ºå ä½ç¬¦è¯´æ˜
    placeholder_help = "\n".join([
        f"- {{{p}}} - {placeholder_descriptions.get(p, 'å ä½ç¬¦')}" 
        for p in available_placeholders
    ])
    
    # æ„å»ºæ ¼å¼è¦æ±‚è¯´æ˜
    format_help = ""
    if format_req:
        if format_req.get("required_format") == "JSON":
            format_help = f"""
## è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆé‡è¦ï¼ï¼‰

**å¿…é¡»è¿”å›JSONæ ¼å¼**ï¼Œç»“æ„å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{', '.join(format_req.get('required_fields', []))}

JSONç»“æ„ç¤ºä¾‹ï¼š
{format_req.get('json_structure', '')}

**é‡è¦æç¤º**ï¼š
- å¿…é¡»åœ¨promptä¸­æ˜ç¡®è¦æ±‚ï¼š"ä»¥ JSON æ ¼å¼è¾“å‡ºç»“æœï¼š"
- å¿…é¡»åœ¨promptæœ«å°¾å¼ºè°ƒï¼š"åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"
- JSONå­—æ®µåå¿…é¡»ä¸ä¸Šè¿°ç»“æ„å®Œå…¨åŒ¹é…
"""
        elif format_req.get("required_format") == "Markdown":
            format_help = """
## è¾“å‡ºæ ¼å¼è¦æ±‚

**è¿”å›Markdownæ ¼å¼çš„æ–‡æœ¬æŠ¥å‘Š**ï¼Œä¸éœ€è¦JSONæ ¼å¼ã€‚
- ä½¿ç”¨æ¸…æ™°çš„ Markdown æ ¼å¼
- åˆç†çš„æ ‡é¢˜å±‚çº§ï¼ˆ# ## ###ï¼‰
- ç»“æ„åŒ–ç»„ç»‡å†…å®¹
"""
    else:
        format_help = """
## è¾“å‡ºæ ¼å¼è¦æ±‚

æ ¹æ®æ™ºèƒ½ä½“èŒè´£ç¡®å®šè¾“å‡ºæ ¼å¼ï¼Œç¡®ä¿æ ¼å¼æ¸…æ™°ã€ç»“æ„åŒ–ã€‚
"""
    
    generation_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Promptå·¥ç¨‹å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œä¸ºæ™ºèƒ½ä½“ç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡çš„Promptæ¨¡æ¿ã€‚

## æ™ºèƒ½ä½“ä¿¡æ¯
- åç§°ï¼š{agent_info.get('name', 'æœªçŸ¥')}
- IDï¼š{payload.agent_id}
- æè¿°ï¼š{agent_info.get('description', 'æ— ')}

## ç”¨æˆ·éœ€æ±‚
{payload.user_requirement}
{style_note}{format_note}

## å¯ç”¨çš„å ä½ç¬¦ï¼ˆå¿…é¡»ä½¿ç”¨å•èŠ±æ‹¬å·ï¼‰

{placeholder_help}

**å ä½ç¬¦ä½¿ç”¨è§„åˆ™**ï¼š
1. å¿…é¡»ä½¿ç”¨å•èŠ±æ‹¬å·æ ¼å¼ï¼š{{variable}}ï¼Œä¸è¦ä½¿ç”¨åŒèŠ±æ‹¬å·
2. åªèƒ½ä½¿ç”¨ä¸Šè¿°åˆ—å‡ºçš„å ä½ç¬¦
3. æ ¹æ®æ™ºèƒ½ä½“ç±»å‹é€‰æ‹©åˆé€‚çš„å ä½ç¬¦
4. ä¸è¦ä½¿ç”¨æœªåˆ—å‡ºçš„å ä½ç¬¦

{format_help}

## ç”Ÿæˆè¦æ±‚
1. Promptåº”è¯¥æ¸…æ™°ã€å…·ä½“ã€å¯æ‰§è¡Œ
2. åŒ…å«æ˜ç¡®çš„è§’è‰²å®šä¹‰ã€ä»»åŠ¡æè¿°ã€è¾“å‡ºè¦æ±‚
3. ä½¿ç”¨ä¸Šè¿°åˆ—å‡ºçš„å ä½ç¬¦ä»¥ä¾¿åŠ¨æ€æ›¿æ¢
4. å¦‚æœç”¨æˆ·éœ€æ±‚ä¸å¤Ÿå…·ä½“ï¼Œå¯ä»¥é€‚å½“è¡¥å……åˆç†çš„å‡è®¾
5. ç¡®ä¿Promptç¬¦åˆè¯¥æ™ºèƒ½ä½“çš„èŒè´£èŒƒå›´
6. ä¿æŒä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€é£æ ¼
7. å¦‚æœæ™ºèƒ½ä½“éœ€è¦JSONæ ¼å¼ï¼Œå¿…é¡»åœ¨promptä¸­æ˜ç¡®è¦æ±‚å¹¶æŒ‡å®šç»“æ„

## è¾“å‡ºæ ¼å¼
è¯·ç›´æ¥è¾“å‡ºç”Ÿæˆçš„Promptå†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€è¯´æ˜æ–‡å­—æˆ–ä»£ç å—æ ‡è®°ã€‚Promptåº”è¯¥å¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚

ç°åœ¨è¯·ç”ŸæˆPromptï¼š"""

    try:
        # è°ƒç”¨LLMç”Ÿæˆprompt
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Promptå·¥ç¨‹å¸ˆï¼Œæ“…é•¿å°†ç”¨æˆ·éœ€æ±‚è½¬åŒ–ä¸ºé«˜è´¨é‡çš„Promptæ¨¡æ¿ã€‚ä½ ç”Ÿæˆçš„Promptåº”è¯¥ç»“æ„æ¸…æ™°ã€æŒ‡ä»¤æ˜ç¡®ã€æ˜“äºæ‰§è¡Œã€‚"
            },
            {
                "role": "user",
                "content": generation_prompt
            }
        ]
        
        generated_prompt, _ = await invoke_llm(
            messages=messages,
            settings=settings,
            temperature=0.7,
        )
        
        # æ¸…ç†ç”Ÿæˆçš„å†…å®¹ï¼ˆç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°ï¼‰
        generated_prompt = generated_prompt.strip()
        if generated_prompt.startswith("```"):
            # ç§»é™¤ä»£ç å—æ ‡è®°
            lines = generated_prompt.split("\n")
            if lines[0].startswith("```"):
                lines = lines[1:]
            if lines[-1].strip() == "```":
                lines = lines[:-1]
            generated_prompt = "\n".join(lines).strip()
        
        # éªŒè¯ç”Ÿæˆçš„prompt
        validation_result = validate_prompt_template(
            prompt=generated_prompt,
            agent_id=payload.agent_id,
            available_placeholders=available_placeholders,
            format_requirements=format_req
        )
        
        # ç”Ÿæˆå»ºè®®çš„æ¨¡æ¿åç§°å’Œæè¿°
        name_suggestion = f"AIç”Ÿæˆ-{agent_info.get('name', 'æ™ºèƒ½ä½“')}"
        description_suggestion = f"æ ¹æ®éœ€æ±‚è‡ªåŠ¨ç”Ÿæˆï¼š{payload.user_requirement[:50]}{'...' if len(payload.user_requirement) > 50 else ''}"
        
        return {
            "success": True,
            "generated_prompt": generated_prompt,
            "suggested_name": name_suggestion,
            "suggested_description": description_suggestion,
            "agent_id": payload.agent_id,
            "agent_name": agent_info.get('name', 'æœªçŸ¥'),
            "validation": validation_result,
        }
        
    except Exception as e:
        logger.error(f"ç”ŸæˆPromptå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ç”ŸæˆPromptå¤±è´¥: {str(e)}"
        )


@app.post("/prompts/extract-keywords")
async def extract_keywords_from_requirement(
    payload: ExtractKeywordsRequest,
    settings: Settings = Depends(get_settings),
) -> Dict[str, Any]:
    """
    ä»ç”¨æˆ·éœ€æ±‚ä¸­æå–å…³é”®æŒ‡ä»¤æˆ–è¯æ±‡
    """
    from .graph_agent import invoke_llm
    
    prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·éœ€æ±‚ï¼Œæå– 5-10 ä¸ªå…³é”®çš„ Prompt æŒ‡ä»¤ã€æ ¸å¿ƒæ¦‚å¿µæˆ–åŠŸèƒ½å…³é”®è¯ã€‚
è¿™äº›å…³é”®è¯å°†ç”¨äºåç»­ç”Ÿæˆæ›´ç²¾ç¡®çš„ Prompt æ¨¡æ¿ã€‚

ç”¨æˆ·éœ€æ±‚ï¼š
{payload.user_requirement}

è¦æ±‚ï¼š
1. åªè¿”å›å…³é”®è¯åˆ—è¡¨
2. å…³é”®è¯åº”è¯¥ç®€çŸ­ã€æœ‰åŠ›ï¼ˆå¦‚"åˆ†æè´¢æŠ¥"ã€"æå–é£é™©"ã€"JSONæ ¼å¼"ï¼‰
3. ç›´æ¥è¿”å› JSON æ•°ç»„æ ¼å¼ï¼Œä¸è¦Markdownæ ‡è®°

è¾“å‡ºç¤ºä¾‹ï¼š
["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"]

è¾“å‡ºï¼š"""

    try:
        messages = [{"role": "user", "content": prompt}]
        reply, _ = await invoke_llm(
            messages=messages,
            settings=settings,
            temperature=0.5,
        )
        
        # æ¸…ç†å’Œè§£æ JSON
        reply = reply.strip()
        if reply.startswith("```"):
            reply = reply.split("\n", 1)[1]
            if reply.endswith("```"):
                reply = reply.rsplit("\n", 1)[0]
        
        # å°è¯•æŸ¥æ‰¾åˆ—è¡¨éƒ¨åˆ†
        start = reply.find("[")
        end = reply.rfind("]")
        if start != -1 and end != -1:
            reply = reply[start:end+1]
            
        import json
        keywords = json.loads(reply)
        
        return {"keywords": keywords}
        
    except Exception as e:
        logger.error(f"æå–å…³é”®è¯å¤±è´¥: {e}", exc_info=True)
        # é™çº§ç­–ç•¥ï¼šç®€å•çš„åŸºäºè§„åˆ™çš„æå–æˆ–è¿”å›ç©ºåˆ—è¡¨
        return {"keywords": [], "error": str(e)}





@app.post("/test-upload")
async def test_upload(files: List[UploadFile] = File(...)):
    """æµ‹è¯•æ–‡ä»¶ä¸Šä¼ æ¥å£"""
    logger.info(f"ğŸ§ª [æµ‹è¯•æ¥å£] æ”¶åˆ° {len(files)} ä¸ªæ–‡ä»¶")
    for idx, f in enumerate(files, 1):
        content = await f.read()
        logger.info(f"   æ–‡ä»¶ {idx}: {f.filename}, å¤§å°: {len(content)} bytes")
    return {"status": "ok", "files": len(files)}


@app.post("/chat/agent/stream-with-files")
async def chat_with_files_stream(
    message: str = Form(""),
    use_knowledge_base: bool = Form(True),
    use_tools: bool = Form(True),
    session_id: Optional[str] = Form(None),
    user_id: Optional[str] = Form(None),
    files: List[UploadFile] = File(...),
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> StreamingResponse:
    """
    æ”¯æŒæ–‡ä»¶ä¸Šä¼ çš„ Agent å¯¹è¯ï¼ˆæµå¼ï¼‰- çœŸæ­£çš„ RAG
    
    ä¸Šä¼ çš„æ–‡ä»¶ä¼šè¢«è§£æã€å‘é‡åŒ–å¹¶å­˜å‚¨åˆ°çŸ¥è¯†åº“ï¼Œç„¶ååŸºäºæ–‡ä»¶å†…å®¹å›ç­”é—®é¢˜
    """
    logger.info(f"=" * 80)
    logger.info(f"ğŸ“ [æ–‡ä»¶ä¸Šä¼  API] æ”¶åˆ°è¯·æ±‚")
    logger.info(f"ğŸ“ æ¶ˆæ¯: {message}")
    logger.info(f"ğŸ“š ä½¿ç”¨çŸ¥è¯†åº“: {use_knowledge_base}")
    logger.info(f"ğŸ”§ ä½¿ç”¨å·¥å…·: {use_tools}")
    logger.info(f"ğŸ“ æ–‡ä»¶æ•°é‡: {len(files)}")
    logger.info(f"ğŸ†” ä¼šè¯ID: {session_id}")
    logger.info(f"ğŸ‘¤ ç”¨æˆ·ID: {user_id}")
    for idx, f in enumerate(files, 1):
        logger.info(f"   æ–‡ä»¶ {idx}: {f.filename} ({f.content_type})")
    logger.info(f"=" * 80)
    
    # è·å–æˆ–ç”Ÿæˆ session_id
    if not session_id:
        session_id = str(uuid.uuid4())
        logger.info(f"ğŸ†” ç”Ÿæˆæ–°çš„ session_id: {session_id}")
    
    file_processor = FileProcessor()
    processed_files = []
    
    # å¤„ç†æ¯ä¸ªä¸Šä¼ çš„æ–‡ä»¶
    for upload_file in files:
        try:
            logger.info(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {upload_file.filename}")
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            file_content = await upload_file.read()
            
            # ä¿å­˜æ–‡ä»¶
            file_path = file_processor.save_file(file_content, upload_file.filename)
            
            # æå–æ–‡æœ¬
            text_content = file_processor.extract_text(file_path)
            
            if text_content and not text_content.startswith("["):
                logger.info(f"ğŸ“ æ–‡æœ¬å†…å®¹é•¿åº¦: {len(text_content)} å­—ç¬¦")
                
                try:
                    # æ–‡æœ¬åˆ†å—
                    logger.info(f"ğŸ”„ å¼€å§‹æ–‡æœ¬åˆ†å—...")
                    chunks = chunk_text(text_content, chunk_size=500, overlap=50)
                    logger.info(f"ğŸ“¦ æ–‡æœ¬åˆ†å—å®Œæˆ: {len(chunks)} ä¸ªå—")
                except Exception as chunk_error:
                    logger.error(f"âŒ æ–‡æœ¬åˆ†å—å¤±è´¥: {chunk_error}", exc_info=True)
                    processed_files.append({
                        "filename": upload_file.filename,
                        "error": f"æ–‡æœ¬åˆ†å—å¤±è´¥: {str(chunk_error)}"
                    })
                    continue
                
                # å‘é‡åŒ–å¹¶å­˜å‚¨åˆ°çŸ¥è¯†åº“
                doc_id = f"file_{upload_file.filename}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                
                successful_chunks = 0
                logger.info(f"ğŸ”„ å¼€å§‹å‘é‡åŒ–å­˜å‚¨åˆ°çŸ¥è¯†åº“...")
                
                for i, chunk in enumerate(chunks):
                    try:
                        chunk_metadata = {
                            "source": upload_file.filename,
                            "chunk_index": i,
                            "total_chunks": len(chunks),
                            "upload_time": datetime.now().isoformat()
                        }
                        
                        logger.debug(f"ğŸ’¾ å‘é‡åŒ–å— {i+1}/{len(chunks)}: {len(chunk)} å­—ç¬¦")
                        
                        ingest_text_chunk(
                            session=session,
                            settings=settings,
                            doc_id=f"{doc_id}_chunk_{i}",
                            content=chunk,
                            metadata=chunk_metadata
                        )
                        successful_chunks += 1
                        
                        if (i + 1) % 10 == 0:
                            logger.info(f"ğŸ’¾ å·²å‘é‡åŒ– {i + 1}/{len(chunks)} ä¸ªå—...")
                    except Exception as chunk_error:
                        logger.error(f"âŒ å— {i} å‘é‡åŒ–å¤±è´¥: {chunk_error}", exc_info=True)
                
                logger.info(f"âœ… æ–‡ä»¶å·²å‘é‡åŒ–: {upload_file.filename}, æˆåŠŸ {successful_chunks}/{len(chunks)} ä¸ªå—")
                
                processed_files.append({
                    "filename": upload_file.filename,
                    "chunks": len(chunks),
                    "characters": len(text_content)
                })
            else:
                logger.warning(f"âš ï¸ æ–‡ä»¶æ— æ³•è§£æ: {upload_file.filename}")
                processed_files.append({
                    "filename": upload_file.filename,
                    "error": text_content
                })
                
        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ {upload_file.filename}: {e}", exc_info=True)
            processed_files.append({
                "filename": upload_file.filename,
                "error": str(e)
            })
    
    logger.info(f"ğŸ“Š æ–‡ä»¶å¤„ç†æ±‡æ€»: æ€»å…± {len(files)} ä¸ªæ–‡ä»¶, æˆåŠŸ {len([f for f in processed_files if 'error' not in f])} ä¸ª")
    
    # æ„å»ºç”¨æˆ·æŸ¥è¯¢
    user_query = message if message else "è¯·åˆ†æè¿™äº›æ–‡ä»¶çš„å†…å®¹å¹¶æ€»ç»“å…³é”®ä¿¡æ¯"
    
    # è·å–å·¥å…·åˆ—è¡¨
    tool_records = list_tools(session)
    if not use_tools:
        tool_records = []
    
    async def event_generator() -> AsyncGenerator[bytes, None]:
        try:
            # å‘é€æ–‡ä»¶å¤„ç†ç»“æœ
            yield format_sse("files_processed", {
                "files": processed_files,
                "total": len(files)
            })
            
            # å‘é€çŠ¶æ€äº‹ä»¶ï¼ŒåŒ…å« session_id ä»¥ä¾¿å‰ç«¯ä¿å­˜
            yield format_sse("status", {
                "stage": "started", 
                "mode": "langgraph_agent_with_files",
                "session_id": session_id
            })
            
            # æµå¼æ‰§è¡Œ LangGraph Agentï¼ˆå¼ºåˆ¶å¯ç”¨çŸ¥è¯†åº“ï¼‰
            async for event in stream_agent(
                user_query=user_query,
                settings=settings,
                session=session,
                tool_records=tool_records,
                use_knowledge_base=True,  # å¼ºåˆ¶å¯ç”¨ï¼Œå› ä¸ºæ–‡ä»¶å·²å­˜å…¥çŸ¥è¯†åº“
                conversation_history=[{"role": "user", "content": user_query}],
                session_id=session_id,
                user_id=user_id,
            ):
                event_type = event.get("event", "unknown")
                
                if event_type == "node_output":
                    node_name = event.get("node", "")
                    node_data = event.get("data", {})
                    
                    yield format_sse("agent_node", {
                        "node": node_name,
                        "status": "completed",
                        "data": node_data,
                        "timestamp": event.get("timestamp")
                    })
                    
                    if "thoughts" in node_data and node_data["thoughts"]:
                        for thought in node_data["thoughts"]:
                            yield format_sse("agent_thought", {
                                "node": node_name,
                                "thought": thought,
                                "timestamp": event.get("timestamp")
                            })
                    
                    if "observations" in node_data and node_data["observations"]:
                        for obs in node_data["observations"]:
                            yield format_sse("agent_observation", {
                                "node": node_name,
                                "observation": obs,
                                "timestamp": event.get("timestamp")
                            })
                    
                    if "tool_results" in node_data:
                        for tool_result in node_data["tool_results"]:
                            yield format_sse("tool_result", {
                                "tool_name": tool_result.get("tool_name"),
                                "output": tool_result.get("output"),
                                "timestamp": event.get("timestamp")
                            })
                    
                    if "contexts" in node_data and node_data["contexts"]:
                        yield format_sse("context", {
                            "items": node_data["contexts"],
                            "count": len(node_data["contexts"])
                        })
                    
                    if node_name == "synthesizer" and "final_answer" in node_data:
                        logger.info("ğŸ“¤ å·²å‘é€æœ€ç»ˆç­”æ¡ˆåˆ°å‰ç«¯ï¼Œé•¿åº¦: %d", len(node_data["final_answer"]))
                        yield format_sse("assistant_final", {
                            "content": node_data["final_answer"]
                        })
                
                elif event_type == "final_answer":
                    final_content = event.get("content", "")
                    yield format_sse("assistant_final", {
                        "content": final_content
                    })
                
                elif event_type == "error":
                    yield format_sse("error", {
                        "message": event.get("message", "Unknown error")
                    })
            
            logger.info("ğŸ“¤ å·²å‘é€å®Œæˆäº‹ä»¶åˆ°å‰ç«¯")
            yield format_sse("completed", {
                "status": "success",
                "files_processed": len(processed_files)
            })
            
        except Exception as e:
            logger.error(f"âŒ æµå¼å¤„ç†é”™è¯¯: {e}", exc_info=True)
            yield format_sse("error", {"message": str(e)})
    
    return StreamingResponse(event_generator(), media_type="text/event-stream")


class ConversationMessage(BaseModel):
    """å¯¹è¯æ¶ˆæ¯æ¨¡å‹ï¼ˆåŒ…å«å¯é€‰çš„å…ƒæ•°æ®ï¼‰"""

    id: str
    user_id: Optional[str]
    session_id: str
    role: str
    content: str
    created_at: datetime
    metadata: Optional[Dict[str, Any]] = None


@app.get("/conversation/{session_id}/history", response_model=List[ConversationMessage])
async def get_conversation_history_api(
    session_id: str,
    user_id: Optional[str] = None,
    limit: int = 20,
    session: Session = Depends(get_db_session),
) -> List[ConversationMessage]:
    """
    è·å–æŒ‡å®šä¼šè¯çš„å¯¹è¯å†å²
    """
    history = get_conversation_history(
        session=session,
        session_id=session_id,
        limit=limit,
        user_id=user_id,
    )

    messages: List[ConversationMessage] = []
    for msg in history:
        metadata: Optional[Dict[str, Any]] = None
        extra = getattr(msg, "extra_metadata", None)
        if extra:
            try:
                metadata = json.loads(extra)
            except Exception:
                metadata = None

        messages.append(
            ConversationMessage(
                id=msg.id,
                user_id=msg.user_id,
                session_id=msg.session_id,
                role=msg.role,
                content=msg.content,
                created_at=msg.created_at,
                metadata=metadata,
            )
        )

    return messages


# ==================== è®°å¿†ç³»ç»Ÿ API ====================

class MemoryItem(BaseModel):
    """è®°å¿†é¡¹æ¨¡å‹"""
    model_config = ConfigDict(from_attributes=True)
    
    id: str
    user_id: Optional[str]
    session_id: Optional[str]
    memory_type: str
    content: str
    importance_score: int
    tags: Optional[list[str]] = None
    access_count: int
    last_accessed_at: Optional[datetime]
    created_at: datetime
    updated_at: datetime


class MemoryCreate(BaseModel):
    """åˆ›å»ºè®°å¿†è¯·æ±‚"""
    content: str
    memory_type: str  # fact/preference/event/relationship
    importance_score: int = 50
    tags: Optional[list[str]] = None
    user_id: Optional[str] = None
    session_id: Optional[str] = None


class MemoryUpdate(BaseModel):
    """æ›´æ–°è®°å¿†è¯·æ±‚"""
    content: Optional[str] = None
    importance_score: Optional[int] = None
    tags: Optional[list[str]] = None


class SessionConfigModel(BaseModel):
    """ä¼šè¯é…ç½®æ¨¡å‹"""
    model_config = ConfigDict(from_attributes=True)
    
    session_id: str
    user_id: Optional[str] = None
    share_memory: bool = True
    auto_extract: bool = True


class UserPreferencesModel(BaseModel):
    """ç”¨æˆ·åå¥½è®¾ç½®æ¨¡å‹"""
    model_config = ConfigDict(from_attributes=True)
    
    user_id: str = "default"
    default_share_memory: bool = True
    default_auto_extract: bool = True


@app.get("/api/memories/search", response_model=List[MemoryItem])
async def search_memories_api(
    query: Optional[str] = None,
    memory_type: Optional[str] = None,
    user_id: Optional[str] = None,
    session_id: Optional[str] = None,
    limit: int = 20,
    session: Session = Depends(get_db_session),
) -> List[MemoryItem]:
    """æœç´¢è®°å¿†"""
    memories = search_memories(
        session=session,
        query=query,
        memory_type=memory_type,
        user_id=user_id,
        session_id=session_id,
        limit=limit,
    )
    
    # è§£æ tags å’Œ metadata
    result = []
    for mem in memories:
        tags = None
        if mem.tags:
            try:
                tags = json.loads(mem.tags)
            except:
                pass
        
        result.append(MemoryItem(
            id=mem.id,
            user_id=mem.user_id,
            session_id=mem.session_id,
            memory_type=mem.memory_type,
            content=mem.content,
            importance_score=mem.importance_score,
            tags=tags,
            access_count=mem.access_count,
            last_accessed_at=mem.last_accessed_at,
            created_at=mem.created_at,
            updated_at=mem.updated_at,
        ))
    
    return result


@app.get("/api/memories/{memory_id}", response_model=MemoryItem)
async def get_memory_api(
    memory_id: str,
    session: Session = Depends(get_db_session),
) -> MemoryItem:
    """è·å–å•æ¡è®°å¿†"""
    memory = get_memory_by_id(session, memory_id)
    if not memory:
        raise HTTPException(status_code=404, detail="è®°å¿†ä¸å­˜åœ¨")
    
    tags = None
    if memory.tags:
        try:
            tags = json.loads(memory.tags)
        except:
            pass
    
    return MemoryItem(
        id=memory.id,
        user_id=memory.user_id,
        session_id=memory.session_id,
        memory_type=memory.memory_type,
        content=memory.content,
        importance_score=memory.importance_score,
        tags=tags,
        access_count=memory.access_count,
        last_accessed_at=memory.last_accessed_at,
        created_at=memory.created_at,
        updated_at=memory.updated_at,
    )


@app.post("/api/memories", response_model=MemoryItem)
async def create_memory_api(
    memory_data: MemoryCreate,
    session: Session = Depends(get_db_session),
    settings: Settings = Depends(get_settings),
) -> MemoryItem:
    """åˆ›å»ºæ–°è®°å¿†"""
    from .memory_service import add_memory_to_vectorstore
    
    memory = create_memory(
        session=session,
        content=memory_data.content,
        memory_type=memory_data.memory_type,
        importance_score=memory_data.importance_score,
        user_id=memory_data.user_id,
        session_id=memory_data.session_id,
        tags=memory_data.tags,
    )
    
    # å‘é‡åŒ–
    add_memory_to_vectorstore(
        memory_id=memory.id,
        content=memory.content,
        memory_type=memory.memory_type,
        user_id=memory.user_id,
        session_id=memory.session_id,
        settings=settings,
    )
    
    tags = None
    if memory.tags:
        try:
            tags = json.loads(memory.tags)
        except:
            pass
    
    return MemoryItem(
        id=memory.id,
        user_id=memory.user_id,
        session_id=memory.session_id,
        memory_type=memory.memory_type,
        content=memory.content,
        importance_score=memory.importance_score,
        tags=tags,
        access_count=memory.access_count,
        last_accessed_at=memory.last_accessed_at,
        created_at=memory.created_at,
        updated_at=memory.updated_at,
    )


@app.put("/api/memories/{memory_id}", response_model=MemoryItem)
async def update_memory_api(
    memory_id: str,
    memory_data: MemoryUpdate,
    session: Session = Depends(get_db_session),
    settings: Settings = Depends(get_settings),
) -> MemoryItem:
    """æ›´æ–°è®°å¿†"""
    from .memory_service import update_memory_in_vectorstore
    
    memory = update_memory(
        session=session,
        memory_id=memory_id,
        content=memory_data.content,
        importance_score=memory_data.importance_score,
        tags=memory_data.tags,
    )
    
    if not memory:
        raise HTTPException(status_code=404, detail="è®°å¿†ä¸å­˜åœ¨")
    
    # å¦‚æœå†…å®¹æ›´æ–°ï¼Œéœ€è¦æ›´æ–°å‘é‡
    if memory_data.content:
        update_memory_in_vectorstore(
            memory_id=memory.id,
            content=memory.content,
            memory_type=memory.memory_type,
            user_id=memory.user_id,
            session_id=memory.session_id,
            settings=settings,
        )
    
    tags = None
    if memory.tags:
        try:
            tags = json.loads(memory.tags)
        except:
            pass
    
    return MemoryItem(
        id=memory.id,
        user_id=memory.user_id,
        session_id=memory.session_id,
        memory_type=memory.memory_type,
        content=memory.content,
        importance_score=memory.importance_score,
        tags=tags,
        access_count=memory.access_count,
        last_accessed_at=memory.last_accessed_at,
        created_at=memory.created_at,
        updated_at=memory.updated_at,
    )


@app.delete("/api/memories/{memory_id}")
async def delete_memory_api(
    memory_id: str,
    session: Session = Depends(get_db_session),
    settings: Settings = Depends(get_settings),
) -> Dict[str, Any]:
    """åˆ é™¤è®°å¿†"""
    success = delete_memory_complete(session, memory_id, settings)
    
    if not success:
        raise HTTPException(status_code=404, detail="è®°å¿†ä¸å­˜åœ¨")
    
    return {"success": True, "message": "è®°å¿†å·²åˆ é™¤"}


@app.delete("/api/memories/batch")
async def delete_memories_batch_api(
    memory_ids: List[str],
    session: Session = Depends(get_db_session),
    settings: Settings = Depends(get_settings),
) -> Dict[str, Any]:
    """æ‰¹é‡åˆ é™¤è®°å¿†"""
    from .memory_service import delete_memory_from_vectorstore
    
    # åˆ é™¤å‘é‡
    for memory_id in memory_ids:
        delete_memory_from_vectorstore(memory_id, settings)
    
    # åˆ é™¤æ•°æ®åº“è®°å½•
    count = delete_memories_batch(session, memory_ids)
    
    return {"success": True, "deleted_count": count}


@app.get("/api/sessions/{session_id}/config", response_model=SessionConfigModel)
async def get_session_config_api(
    session_id: str,
    session: Session = Depends(get_db_session),
) -> SessionConfigModel:
    """è·å–ä¼šè¯é…ç½®"""
    config = get_session_config(session, session_id)
    
    if not config:
        # åˆ›å»ºé»˜è®¤é…ç½®
        config = update_session_config(
            session=session,
            session_id=session_id,
            share_memory=True,
            auto_extract=True,
        )
    
    return SessionConfigModel.model_validate(config)


@app.put("/api/sessions/{session_id}/config", response_model=SessionConfigModel)
async def update_session_config_api(
    session_id: str,
    config_data: SessionConfigModel,
    session: Session = Depends(get_db_session),
) -> SessionConfigModel:
    """æ›´æ–°ä¼šè¯é…ç½®"""
    config = update_session_config(
        session=session,
        session_id=session_id,
        share_memory=config_data.share_memory,
        auto_extract=config_data.auto_extract,
        user_id=config_data.user_id,
    )
    
    return SessionConfigModel.model_validate(config)


@app.post("/api/memories/extract")
async def extract_memories_api(
    conversation_text: str,
    session_id: str,
    user_id: Optional[str] = None,
    settings: Settings = Depends(get_settings),
) -> Dict[str, Any]:
    """æ‰‹åŠ¨è§¦å‘è®°å¿†æå–"""
    memories = await extract_memories_from_conversation(
        conversation_text=conversation_text,
        settings=settings,
        session_id=session_id,
        user_id=user_id,
    )
    
    return {
        "success": True,
        "extracted_count": len(memories),
        "memories": memories,
    }


@app.post("/api/memories/reindex")
async def reindex_memories_api(
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> Dict[str, Any]:
    """
    é‡æ–°ç´¢å¼•æ‰€æœ‰è®°å¿†åˆ°å‘é‡åº“
    ä¿®å¤æ—§è®°å¿†çš„ metadata æ ¼å¼é—®é¢˜
    """
    from .memory_service import add_memory_to_vectorstore
    
    try:
        # è·å–æ‰€æœ‰è®°å¿†
        all_memories = search_memories(session=session, limit=10000)
        
        reindexed_count = 0
        failed_count = 0
        
        for memory in all_memories:
            try:
                # é‡æ–°æ·»åŠ åˆ°å‘é‡åº“ï¼ˆä½¿ç”¨æ–°çš„ metadata æ ¼å¼ï¼‰
                add_memory_to_vectorstore(
                    memory_id=memory.id,
                    content=memory.content,
                    memory_type=memory.memory_type,
                    user_id=memory.user_id,
                    session_id=memory.session_id,
                    settings=settings,
                )
                reindexed_count += 1
            except Exception as e:
                logger.error(f"é‡æ–°ç´¢å¼•è®°å¿† {memory.id} å¤±è´¥: {e}")
                failed_count += 1
        
        logger.info(f"âœ… è®°å¿†é‡æ–°ç´¢å¼•å®Œæˆï¼šæˆåŠŸ={reindexed_count}, å¤±è´¥={failed_count}")
        
        return {
            "success": True,
            "reindexed_count": reindexed_count,
            "failed_count": failed_count,
            "total_memories": len(all_memories),
        }
    
    except Exception as e:
        logger.error(f"è®°å¿†é‡æ–°ç´¢å¼•å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é‡æ–°ç´¢å¼•å¤±è´¥: {str(e)}")


@app.post("/api/memories/deduplicate")
async def deduplicate_memories_api(
    threshold: float = 0.7,
    dry_run: bool = False,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> Dict[str, Any]:
    """
    æ¸…ç†é‡å¤çš„è®°å¿†
    
    Args:
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œé»˜è®¤ 0.7
        dry_run: ä»…æ£€æµ‹ä¸åˆ é™¤ï¼Œé»˜è®¤ False
    """
    from .memory_service import (
        calculate_text_similarity,
        calculate_jaccard_similarity,
        delete_memory_complete,
    )
    
    try:
        # è·å–æ‰€æœ‰è®°å¿†
        all_memories = search_memories(session=session, limit=10000)
        
        duplicates = []
        processed = set()
        
        # æŒ‰ç±»å‹åˆ†ç»„
        by_type = {}
        for mem in all_memories:
            if mem.memory_type not in by_type:
                by_type[mem.memory_type] = []
            by_type[mem.memory_type].append(mem)
        
        # æ£€æµ‹æ¯ä¸ªç±»å‹ä¸­çš„é‡å¤
        for memory_type, memories in by_type.items():
            for i, mem1 in enumerate(memories):
                if mem1.id in processed:
                    continue
                
                for mem2 in memories[i+1:]:
                    if mem2.id in processed:
                        continue
                    
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    text_sim = calculate_text_similarity(mem1.content, mem2.content)
                    jaccard_sim = calculate_jaccard_similarity(mem1.content, mem2.content)
                    combined_sim = text_sim * 0.6 + jaccard_sim * 0.4
                    
                    if combined_sim >= threshold:
                        # ä¿ç•™è¾ƒæ—©åˆ›å»ºçš„æˆ–è®¿é—®æ¬¡æ•°æ›´å¤šçš„
                        if mem1.access_count >= mem2.access_count:
                            keep, remove = mem1, mem2
                        else:
                            keep, remove = mem2, mem1
                        
                        duplicates.append({
                            "keep_id": keep.id,
                            "keep_content": keep.content[:100],
                            "keep_access_count": keep.access_count,
                            "remove_id": remove.id,
                            "remove_content": remove.content[:100],
                            "similarity": round(combined_sim, 3)
                        })
                        
                        processed.add(remove.id)
        
        # åˆ é™¤é‡å¤è®°å¿†
        deleted_count = 0
        if not dry_run:
            for dup in duplicates:
                try:
                    delete_memory_complete(session, dup["remove_id"], settings)
                    deleted_count += 1
                except Exception as e:
                    logger.error(f"åˆ é™¤é‡å¤è®°å¿† {dup['remove_id']} å¤±è´¥: {e}")
        
        result = {
            "success": True,
            "total_memories": len(all_memories),
            "duplicates_found": len(duplicates),
            "deleted_count": deleted_count if not dry_run else 0,
            "dry_run": dry_run,
            "duplicates": duplicates[:20],  # åªè¿”å›å‰20ä¸ª
        }
        
        if dry_run:
            result["message"] = f"æ£€æµ‹åˆ° {len(duplicates)} å¯¹é‡å¤è®°å¿†ï¼Œä½¿ç”¨ dry_run=false æ¥åˆ é™¤"
        else:
            result["message"] = f"æˆåŠŸåˆ é™¤ {deleted_count} æ¡é‡å¤è®°å¿†"
        
        logger.info(f"âœ… è®°å¿†å»é‡å®Œæˆï¼šæ‰¾åˆ° {len(duplicates)} å¯¹ï¼Œåˆ é™¤ {deleted_count} æ¡")
        
        return result
    
    except Exception as e:
        logger.error(f"è®°å¿†å»é‡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å»é‡å¤±è´¥: {str(e)}")


# ==================== ç”¨æˆ·åå¥½è®¾ç½® API ====================

@app.get("/api/preferences", response_model=UserPreferencesModel)
async def get_preferences_api(
    user_id: str = "default",
    session: Session = Depends(get_db_session),
) -> UserPreferencesModel:
    """è·å–ç”¨æˆ·åå¥½è®¾ç½®"""
    prefs = get_user_preferences(session, user_id)
    
    if not prefs:
        # åˆ›å»ºé»˜è®¤åå¥½
        prefs = update_user_preferences(
            session=session,
            user_id=user_id,
            default_share_memory=True,
            default_auto_extract=True,
        )
    
    return UserPreferencesModel.model_validate(prefs)


@app.put("/api/preferences", response_model=UserPreferencesModel)
async def update_preferences_api(
    prefs_data: UserPreferencesModel,
    session: Session = Depends(get_db_session),
) -> UserPreferencesModel:
    """
    æ›´æ–°ç”¨æˆ·åå¥½è®¾ç½®
    ä¿®æ”¹åï¼Œæ‰€æœ‰æ–°å»ºçš„ä¼šè¯éƒ½å°†ä½¿ç”¨è¿™äº›é»˜è®¤è®¾ç½®
    """
    prefs = update_user_preferences(
        session=session,
        user_id=prefs_data.user_id,
        default_share_memory=prefs_data.default_share_memory,
        default_auto_extract=prefs_data.default_auto_extract,
    )
    
    logger.info(
        f"âœ… ç”¨æˆ·åå¥½å·²æ›´æ–°: user_id={prefs_data.user_id}, "
        f"share_memory={prefs_data.default_share_memory}, "
        f"auto_extract={prefs_data.default_auto_extract}"
    )
    
    return UserPreferencesModel.model_validate(prefs)


# ==================== ä¼šè¯ç®¡ç† API ====================

class ConversationSession(BaseModel):
    """ä¼šè¯æ‘˜è¦ä¿¡æ¯"""
    model_config = ConfigDict(from_attributes=True)
    
    session_id: str
    title: str
    message_count: int
    first_message_time: Optional[str]
    last_message_time: Optional[str]
    preview: str


@app.get("/conversations", response_model=List[ConversationSession])
async def list_conversations(
    user_id: Optional[str] = None,
    limit: int = 50,
    offset: int = 0,
    session: Session = Depends(get_db_session),
) -> List[ConversationSession]:
    """
    åˆ—å‡ºæ‰€æœ‰ä¼šè¯åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰
    """
    sessions = list_conversation_sessions(
        session=session,
        user_id=user_id,
        limit=limit,
        offset=offset,
    )
    
    return [ConversationSession.model_validate(s) for s in sessions]


@app.get("/conversations/search", response_model=List[ConversationSession])
async def search_conversations(
    q: str,
    user_id: Optional[str] = None,
    limit: int = 20,
    session: Session = Depends(get_db_session),
) -> List[ConversationSession]:
    """
    æœç´¢ä¼šè¯ï¼ˆåŸºäºå¯¹è¯å†…å®¹ï¼‰
    """
    sessions = search_conversation_sessions(
        session=session,
        query=q,
        user_id=user_id,
        limit=limit,
    )
    
    return [ConversationSession.model_validate(s) for s in sessions]


@app.delete("/conversation/{session_id}")
async def delete_conversation_api(
    session_id: str,
    user_id: Optional[str] = None,
    session: Session = Depends(get_db_session),
) -> Dict[str, Any]:
    """
    åˆ é™¤æ•´ä¸ªä¼šè¯
    """
    count = delete_conversation_session(
        session=session,
        session_id=session_id,
        user_id=user_id,
    )
    
    return {
        "success": True,
        "deleted_count": count,
        "session_id": session_id,
    }


@app.delete("/conversation/message/{message_id}")
async def delete_message_api(
    message_id: str,
    user_id: Optional[str] = None,
    session: Session = Depends(get_db_session),
) -> Dict[str, Any]:
    """
    åˆ é™¤å•æ¡æ¶ˆæ¯
    """
    success = delete_conversation_message(
        session=session,
        message_id=message_id,
        user_id=user_id,
    )
    
    return {
        "success": success,
        "message_id": message_id,
    }


# ==================== å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ API ====================

class MultiAgentChatRequest(BaseModel):
    """å¤šæ™ºèƒ½ä½“å¯¹è¯è¯·æ±‚"""
    messages: List[Message]
    use_knowledge_base: bool = Field(default=True, description="æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“")
    use_tools: bool = Field(default=True, description="æ˜¯å¦ä½¿ç”¨å·¥å…·")
    execution_mode: str = Field(default="sequential", description="æ‰§è¡Œæ¨¡å¼ï¼šsequential æˆ– parallel")
    session_id: Optional[str] = Field(default=None, description="ä¼šè¯ID")
    user_id: Optional[str] = Field(default=None, description="ç”¨æˆ·ID")


class MultiAgentChatResponse(BaseModel):
    """å¤šæ™ºèƒ½ä½“å¯¹è¯å“åº”"""
    reply: str
    orchestrator_plan: str
    sub_tasks: List[Dict[str, Any]] = Field(default_factory=list)
    agent_results: Dict[str, Dict[str, Any]] = Field(default_factory=dict)
    thoughts: List[str] = Field(default_factory=list)
    observations: List[str] = Field(default_factory=list)
    quality_score: float = 0.0
    thread_id: str
    session_id: str


@app.post("/chat/multi-agent", response_model=MultiAgentChatResponse)
async def chat_with_multi_agent(
    payload: MultiAgentChatRequest,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> MultiAgentChatResponse:
    """
    ä½¿ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¤„ç†å¯¹è¯
    
    ç‰¹ç‚¹ï¼š
    - å¤šä¸ªä¸“å®¶æ™ºèƒ½ä½“åä½œ
    - ä»»åŠ¡è‡ªåŠ¨åˆ†è§£
    - å¹¶è¡Œ/ä¸²è¡Œæ‰§è¡Œ
    - ç»“æœæ™ºèƒ½æ±‡æ€»
    """
    user_query = payload.messages[-1].content if payload.messages else ""
    session_id = payload.session_id or str(uuid.uuid4())

    # âš¡ æ™ºèƒ½è·¯ç”±ï¼šç®€å•é—®é¢˜èµ°å¿«é€Ÿè·¯å¾„
    if is_simple_query(user_query):
        logger.info(f"âš¡ [å¿«é€Ÿæ¨¡å¼] æ£€æµ‹åˆ°ç®€å•é—®é¢˜ï¼Œä½¿ç”¨ç›´æ¥å›å¤: {user_query[:50]}...")

        from .graph_agent import invoke_llm

        # ç›´æ¥ç”¨ä¸€æ¬¡LLMè°ƒç”¨å›ç­”ç®€å•é—®é¢˜
        quick_prompt = f"""è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ä¿æŒç®€æ´å‹å¥½ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{user_query}

è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼š"""

        try:
            quick_answer, _ = await invoke_llm(
                messages=[{"role": "user", "content": quick_prompt}],
                settings=settings,
                temperature=0.7,
                max_tokens=500,  # ç®€å•é—®é¢˜ä¸éœ€è¦å¤ªé•¿çš„å›å¤
            )

            return MultiAgentChatResponse(
                reply=quick_answer,
                orchestrator_plan="[å¿«é€Ÿæ¨¡å¼] ç®€å•é—®é¢˜ï¼Œç›´æ¥å›å¤",
                sub_tasks=[],
                agent_results={},
                thoughts=["æ£€æµ‹åˆ°ç®€å•é—®é¢˜ï¼Œä½¿ç”¨å¿«é€Ÿå›å¤æ¨¡å¼"],
                observations=[],
                quality_score=0.9,
                thread_id=str(uuid.uuid4()),
                session_id=session_id,
            )
        except Exception as e:
            logger.warning(f"å¿«é€Ÿæ¨¡å¼å¤±è´¥ï¼Œå›é€€åˆ°å¤šæ™ºèƒ½ä½“: {e}")

    # å¤æ‚é—®é¢˜èµ°å¤šæ™ºèƒ½ä½“æµç¨‹
    logger.info("ğŸ¤–ğŸ¤–ğŸ¤– [å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ] å¼€å§‹å¤„ç†è¯·æ±‚")

    from .multi_agent import run_multi_agent

    tool_records = []
    if payload.use_tools:
        tool_records = list_tools(session, include_inactive=False)

    result = await run_multi_agent(
        user_query=user_query,
        settings=settings,
        session=session,
        tool_records=tool_records,
        use_knowledge_base=payload.use_knowledge_base,
        conversation_history=[msg.model_dump() for msg in payload.messages],
        session_id=session_id,
        user_id=payload.user_id,
        execution_mode=payload.execution_mode,
    )

    return MultiAgentChatResponse(
        reply=result.get("final_answer", "æœªèƒ½ç”Ÿæˆç­”æ¡ˆ"),
        orchestrator_plan=result.get("orchestrator_plan", ""),
        sub_tasks=result.get("sub_tasks", []),
        agent_results=result.get("agent_results", {}),
        thoughts=result.get("thoughts", []),
        observations=result.get("observations", []),
        quality_score=result.get("quality_score", 0.0),
        thread_id=result.get("thread_id", ""),
        session_id=result.get("session_id", ""),
    )


@app.post("/chat/multi-agent/stream")
async def chat_with_multi_agent_stream(
    payload: MultiAgentChatRequest,
    settings: Settings = Depends(get_settings),
    session: Session = Depends(get_db_session),
) -> StreamingResponse:
    """
    ä½¿ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¤„ç†å¯¹è¯ï¼ˆæµå¼ï¼‰

    å®æ—¶è¿”å›å„æ™ºèƒ½ä½“çš„æ‰§è¡Œè¿‡ç¨‹
    """
    user_query = payload.messages[-1].content if payload.messages else ""
    session_id = payload.session_id or str(uuid.uuid4())

    # âš¡ æ™ºèƒ½è·¯ç”±ï¼šç®€å•é—®é¢˜èµ°å¿«é€Ÿè·¯å¾„
    if is_simple_query(user_query):
        logger.info(f"âš¡ [å¿«é€Ÿæ¨¡å¼-æµå¼] æ£€æµ‹åˆ°ç®€å•é—®é¢˜: {user_query[:50]}...")

        from .graph_agent import invoke_llm

        async def quick_event_generator() -> AsyncGenerator[bytes, None]:
            try:
                yield format_sse("status", {"stage": "started", "mode": "quick_reply"})
                yield format_sse("orchestrator_plan", {
                    "plan": "[å¿«é€Ÿæ¨¡å¼] ç®€å•é—®é¢˜ï¼Œç›´æ¥å›å¤",
                    "timestamp": datetime.now().isoformat(),
                })

                # ç›´æ¥ç”¨ä¸€æ¬¡LLMè°ƒç”¨
                quick_prompt = f"""è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ä¿æŒç®€æ´å‹å¥½ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{user_query}

è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼š"""

                quick_answer, _ = await invoke_llm(
                    messages=[{"role": "user", "content": quick_prompt}],
                    settings=settings,
                    temperature=0.7,
                    max_tokens=500,
                )

                # å‘é€ç­”æ¡ˆ
                yield format_sse("assistant_final", {"content": quick_answer})
                yield format_sse("completed", {
                    "thread_id": str(uuid.uuid4()),
                    "timestamp": datetime.now().isoformat(),
                })

            except Exception as e:
                logger.error(f"å¿«é€Ÿæ¨¡å¼å¤±è´¥: {e}")
                yield format_sse("error", {"message": str(e)})

        return StreamingResponse(quick_event_generator(), media_type="text/event-stream")

    # å¤æ‚é—®é¢˜èµ°å¤šæ™ºèƒ½ä½“æµç¨‹
    logger.info("ğŸŒŠğŸ¤–ğŸ¤–ğŸ¤– [å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ-æµå¼] å¼€å§‹å¤„ç†")

    from .multi_agent import stream_multi_agent

    tool_records = []
    if payload.use_tools:
        tool_records = list_tools(session, include_inactive=False)

    async def event_generator() -> AsyncGenerator[bytes, None]:
        try:
            yield format_sse("status", {"stage": "started", "mode": "multi_agent"})

            async for event in stream_multi_agent(
                user_query=user_query,
                settings=settings,
                session=session,
                tool_records=tool_records,
                use_knowledge_base=payload.use_knowledge_base,
                conversation_history=[msg.model_dump() for msg in payload.messages],
                session_id=session_id,
                user_id=payload.user_id,
                execution_mode=payload.execution_mode,
            ):
                event_type = event.get("event", "unknown")

                if event_type == "orchestrator_plan":
                    yield format_sse("orchestrator_plan", {
                        "plan": event.get("data", {}).get("orchestrator_plan", ""),
                        "timestamp": event.get("timestamp"),
                    })

                elif event_type == "agent_execution":
                    node_name = event.get("node", "")
                    node_data = event.get("data", {})

                    yield format_sse("agent_execution", {
                        "agent": node_name,
                        "data": node_data,
                        "timestamp": event.get("timestamp"),
                    })

                    if "final_answer" in node_data and node_data["final_answer"]:
                        yield format_sse("assistant_final", {
                            "content": node_data["final_answer"],
                        })
                        logger.info(f"ğŸ“¤ å¤šæ™ºèƒ½ä½“æ¨¡å¼ï¼šå·²å‘é€æœ€ç»ˆç­”æ¡ˆï¼Œé•¿åº¦: {len(node_data['final_answer'])}")

                elif event_type == "completed":
                    yield format_sse("completed", {
                        "thread_id": event.get("thread_id"),
                        "timestamp": event.get("timestamp"),
                    })

        except Exception as e:
            logger.error(f"å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæµå¼æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            yield format_sse("error", {"message": str(e)})

    return StreamingResponse(event_generator(), media_type="text/event-stream")


@app.get("/multi-agent/agents")
async def list_multi_agent_agents() -> List[Dict[str, Any]]:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ™ºèƒ½ä½“
    """
    from .agent_roles import list_available_agents
    return list_available_agents()
