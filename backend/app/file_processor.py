"""
æ–‡ä»¶å¤„ç†æ¨¡å— - æ”¯æŒ PDFã€Wordã€TXTã€å›¾ç‰‡ç­‰æ–‡ä»¶çš„è§£æå’Œå‘é‡åŒ–
"""
import os
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path
import hashlib
from datetime import datetime

logger = logging.getLogger(__name__)


class FileProcessor:
    """æ–‡ä»¶å¤„ç†å™¨ - è§£æå„ç§æ ¼å¼æ–‡ä»¶å¹¶æå–æ–‡æœ¬"""
    
    def __init__(self, upload_dir: str = "data/uploads"):
        # ä½¿ç”¨ç›¸å¯¹äºå½“å‰æ–‡ä»¶çš„è·¯å¾„
        current_dir = Path(__file__).parent.parent  # backend/app -> backend
        self.upload_dir = current_dir / upload_dir
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"ğŸ“ æ–‡ä»¶ä¸Šä¼ ç›®å½•: {self.upload_dir.absolute()}")
        
    def save_file(self, file_content: bytes, filename: str) -> str:
        """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶"""
        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_filename = f"{timestamp}_{filename}"
        file_path = self.upload_dir / safe_filename
        
        with open(file_path, "wb") as f:
            f.write(file_content)
        
        logger.info(f"âœ… æ–‡ä»¶å·²ä¿å­˜: {file_path}")
        return str(file_path)
    
    def extract_text(self, file_path: str) -> str:
        """ä»æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹"""
        file_path = Path(file_path)
        extension = file_path.suffix.lower()
        
        try:
            if extension == ".txt":
                return self._extract_from_txt(file_path)
            elif extension == ".pdf":
                return self._extract_from_pdf(file_path)
            elif extension in [".doc", ".docx"]:
                return self._extract_from_word(file_path)
            elif extension in [".jpg", ".jpeg", ".png", ".bmp"]:
                return self._extract_from_image(file_path)
            else:
                logger.warning(f"âš ï¸ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {extension}")
                return f"[ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {extension}]"
        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶è§£æå¤±è´¥ {file_path}: {e}")
            return f"[æ–‡ä»¶è§£æå¤±è´¥: {str(e)}]"
    
    def _extract_from_txt(self, file_path: Path) -> str:
        """æå– TXT æ–‡ä»¶å†…å®¹"""
        try:
            # å°è¯•å¤šç§ç¼–ç 
            for encoding in ['utf-8', 'gbk', 'gb2312', 'latin-1']:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    logger.info(f"âœ… æˆåŠŸè¯»å– TXT (ç¼–ç : {encoding})")
                    return content
                except UnicodeDecodeError:
                    continue
            
            logger.warning("âš ï¸ æ‰€æœ‰ç¼–ç å°è¯•å¤±è´¥ï¼Œä½¿ç”¨ latin-1 å¼ºåˆ¶è¯»å–")
            with open(file_path, 'r', encoding='latin-1') as f:
                return f.read()
        except Exception as e:
            raise Exception(f"TXT æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    
    def _extract_from_pdf(self, file_path: Path) -> str:
        """æå– PDF æ–‡ä»¶å†…å®¹"""
        try:
            import PyPDF2
            
            text_parts = []
            with open(file_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                num_pages = len(pdf_reader.pages)
                
                logger.info(f"ğŸ“– å¼€å§‹æå– PDFï¼Œå…± {num_pages} é¡µ")
                
                for page_num in range(min(num_pages, 50)):  # æœ€å¤šæå–å‰50é¡µï¼Œé¿å…å¤ªé•¿
                    page = pdf_reader.pages[page_num]
                    text = page.extract_text()
                    if text.strip():
                        text_parts.append(text)
                
                if num_pages > 50:
                    logger.warning(f"âš ï¸ PDF å¤ªé•¿ï¼Œä»…æå–å‰ 50 é¡µï¼ˆå…± {num_pages} é¡µï¼‰")
            
            result = "\n\n".join(text_parts)
            logger.info(f"âœ… æˆåŠŸæå– PDFï¼Œå…± {min(num_pages, 50)} é¡µï¼Œ{len(result)} å­—ç¬¦")
            return result if result else "[PDF æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•æå–æ–‡æœ¬]"
            
        except ImportError:
            logger.error("âŒ PyPDF2 æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install PyPDF2")
            return "[éœ€è¦å®‰è£… PyPDF2: pip install PyPDF2]"
        except Exception as e:
            logger.error(f"âŒ PDF è§£æå¼‚å¸¸: {e}")
            raise Exception(f"PDF è§£æå¤±è´¥: {e}")
    
    def _extract_from_word(self, file_path: Path) -> str:
        """æå– Word æ–‡ä»¶å†…å®¹"""
        try:
            import docx
            
            doc = docx.Document(file_path)
            paragraphs = [para.text for para in doc.paragraphs if para.text.strip()]
            
            # æå–è¡¨æ ¼
            tables_text = []
            for table in doc.tables:
                for row in table.rows:
                    row_text = " | ".join(cell.text.strip() for cell in row.cells)
                    if row_text.strip():
                        tables_text.append(row_text)
            
            content_parts = []
            if paragraphs:
                content_parts.append("\n".join(paragraphs))
            if tables_text:
                content_parts.append("\n--- è¡¨æ ¼å†…å®¹ ---\n" + "\n".join(tables_text))
            
            result = "\n\n".join(content_parts)
            logger.info(f"âœ… æˆåŠŸæå– Wordï¼Œ{len(paragraphs)} æ®µè½ï¼Œ{len(result)} å­—ç¬¦")
            return result if result else "[Word æ–‡ä»¶ä¸ºç©º]"
            
        except ImportError:
            logger.error("âŒ python-docx æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install python-docx")
            return "[éœ€è¦å®‰è£… python-docx: pip install python-docx]"
        except Exception as e:
            raise Exception(f"Word è§£æå¤±è´¥: {e}")
    
    def _extract_from_image(self, file_path: Path) -> str:
        """æå–å›¾ç‰‡ä¸­çš„æ–‡å­—ï¼ˆOCRï¼‰"""
        logger.warning("âš ï¸ å›¾ç‰‡ OCR åŠŸèƒ½éœ€è¦ pytesseractï¼Œæš‚ä¸æ”¯æŒ")
        return f"[å›¾ç‰‡æ–‡ä»¶: {file_path.name}ï¼ŒOCR åŠŸèƒ½å¾…å®ç°]"
    
    def calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶ MD5 å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡"""
        with open(file_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()


def chunk_text(text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
    """å°†é•¿æ–‡æœ¬åˆ†å‰²æˆå°å—"""
    if len(text) <= chunk_size:
        return [text]
    
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        
        # å°è¯•åœ¨å¥å·ã€æ¢è¡Œç¬¦ç­‰å¤„åˆ†å‰²
        if end < len(text):
            for delimiter in ['ã€‚\n', 'ã€‚', '\n\n', '\n', 'ï¼›', 'ï¼›']:
                split_pos = text.rfind(delimiter, start, end)
                if split_pos > start:
                    end = split_pos + len(delimiter)
                    break
        
        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)
        
        start = end - overlap
    
    logger.info(f"âœ… æ–‡æœ¬åˆ†å—å®Œæˆ: {len(text)} å­—ç¬¦ â†’ {len(chunks)} ä¸ªå—")
    return chunks

